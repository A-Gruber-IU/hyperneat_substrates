{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31ec82b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import jax\n",
    "import jax.numpy as jnp\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorneat.algorithm.neat import NEAT\n",
    "from tensorneat.algorithm.hyperneat import HyperNEAT, FullSubstrate\n",
    "from tensorneat.genome import DefaultGenome\n",
    "from tensorneat.genome.operations import DefaultMutation\n",
    "from tensorneat.genome.gene import DefaultConn\n",
    "from brax_env import CustomBraxEnv\n",
    "from tensorneat.common import ACT\n",
    "from dim_tuning.pca_dim_mapping import PCAanalyzer \n",
    "from data_sampling import collect_random_policy_data, collect_expert_policy_data\n",
    "\n",
    "import wandb\n",
    "from custom_pipeline import CustomPipeline\n",
    "from dim_tuning.manual_dim_mapping import SubstrateGenerator\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5600ab28",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# change log\n",
    "# manual mapping for ant --- worse than without\n",
    "# lower survival threshold, higher mutation rates --- no significant improvement\n",
    "# mutation rates changed back to lower values, additional hidden layers (2 to 4) with only one_double_hot (two_hot before), higher pop size --- faster convergence, end result same\n",
    "# lower survival threshold, more gens, species fitness mean (before max) --- hardly any improvement in max fitness for 20 gen, then similiar with decreasing variance (nice convergence)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "630408d1",
   "metadata": {},
   "source": [
    "Tested [Brax environments](https://github.com/google/brax/tree/main/brax/envs):\n",
    "* ant\n",
    "* halfcheetah\n",
    "* swimmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8d861aa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "ENV_NAME = \"ant\"\n",
    "WANDB_NAME_SUFFIX = \"man\"\n",
    "\n",
    "ENV_BACKEND = \"generalized\"  # ['generalized', 'positional', 'spring']\n",
    "MAX_STEP = 5000\n",
    "FITNESS_TARGET = 5000.0\n",
    "\n",
    "GENERATION_LIMIT = 50\n",
    "POP_SIZE = 600\n",
    "SPECIES_SIZE = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24087bcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "HIDDEN_LAYER_TYPE = \"one_double_hot\"        # [\"shift\" / \"one_hot\" / \"two_hot\" / \"one_double_hot\"], defaults to one_hot\n",
    "HIDDEN_DEPTH = 4                            # >=1\n",
    "\n",
    "REPEAT_TIMES = 5 \n",
    "WEIGHT_TRESHOLD = 0.0\n",
    "\n",
    "ALL_ENV_SPECIFIC_ARGS = {\n",
    "    \"ant\": {\n",
    "        \"healthy_reward\": 0.1,\n",
    "        \"ctrl_cost_weight\": 0.1,\n",
    "        \"contact_cost_weight\": 5e-4\n",
    "    },\n",
    "    \"halfcheetah\": {\n",
    "        \"forward_reward_weight\": 2.0,\n",
    "        \"ctrl_cost_weight\": 0.05\n",
    "    },\n",
    "    \"swimmer\": {\n",
    "        \"ctrl_cost_weight\": 0.0001\n",
    "    }\n",
    "}\n",
    "\n",
    "env_specific_args = ALL_ENV_SPECIFIC_ARGS.get(ENV_NAME, {})\n",
    "\n",
    "\n",
    "expert_sample_config = {\n",
    "    \"generation_limit\": 20,\n",
    "    \"pop_size\": 500,\n",
    "    \"species_size\": 10,\n",
    "    \"hidden_depth\": 1,\n",
    "    \"weight_threshold\": WEIGHT_TRESHOLD,\n",
    "    \"fitness_target\": FITNESS_TARGET,\n",
    "    \"env_args\": env_specific_args\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "79b4677d",
   "metadata": {},
   "outputs": [],
   "source": [
    "OUTPUT_DIR = f\"output/{ENV_NAME}\"\n",
    "if not os.path.exists(f\"output\"):\n",
    "    os.mkdir(\"output\")\n",
    "if not os.path.exists(f\"{OUTPUT_DIR}\"):\n",
    "    os.mkdir(f\"{OUTPUT_DIR}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "88a29815",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/andi/anaconda3/envs/jax/lib/python3.10/site-packages/brax/io/mjcf.py:480: UserWarning: Brax System, piplines and environments are not actively being maintained. Please see MJX for a well maintained JAX-based physics engine: https://github.com/google-deepmind/mujoco/tree/main/mjx. For a host of environments that use MJX, see: https://github.com/google-deepmind/mujoco_playground.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "env_problem = CustomBraxEnv(\n",
    "    env_name=ENV_NAME,\n",
    "    backend=ENV_BACKEND,\n",
    "    brax_args=env_specific_args,\n",
    "    max_step=MAX_STEP,\n",
    "    repeat_times=REPEAT_TIMES,\n",
    "    obs_normalization=False,\n",
    "    sample_episodes=16,\n",
    "    )\n",
    "obs_size = env_problem.input_shape[0]\n",
    "act_size = env_problem.output_shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d0533cb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Starting Expert Training and Data Collection ---\n",
      "--> Step 1: Configuring and training the expert agent...\n",
      "Qurey dimension for sampling:  4\n",
      "initializing\n",
      "initializing finished\n",
      "start compile\n",
      "compile finished, cost time: 23.670351s\n",
      "Generation: 1, Cost time: 7564.17ms\n",
      " \tfitness: valid cnt: 250, max: 0.9278, min: -679.2310, mean: -67.0915, std: 88.0607\n",
      "\n",
      "\tnode counts: max: 6, min: 5, mean: 5.24\n",
      " \tconn counts: max: 6, min: 2, mean: 4.04\n",
      " \tspecies: 10, [98, 1, 5, 1, 1, 4, 1, 2, 77, 60]\n",
      "\n",
      "Generation: 2, Cost time: 7531.68ms\n",
      " \tfitness: valid cnt: 250, max: 4.4747, min: -514.6193, mean: -47.0727, std: 70.8256\n",
      "\n",
      "\tnode counts: max: 7, min: 5, mean: 5.52\n",
      " \tconn counts: max: 7, min: 2, mean: 4.05\n",
      " \tspecies: 10, [34, 21, 31, 14, 11, 37, 10, 6, 4, 82]\n",
      "\n",
      "Generation: 3, Cost time: 7545.05ms\n",
      " \tfitness: valid cnt: 250, max: 2.8163, min: -440.7481, mean: -47.5011, std: 70.5651\n",
      "\n",
      "\tnode counts: max: 8, min: 5, mean: 5.69\n",
      " \tconn counts: max: 7, min: 1, mean: 4.00\n",
      " \tspecies: 10, [21, 16, 21, 22, 10, 21, 19, 24, 16, 80]\n",
      "\n",
      "Generation: 4, Cost time: 7519.63ms\n",
      " \tfitness: valid cnt: 250, max: 8.1760, min: -493.0459, mean: -30.6942, std: 54.5812\n",
      "\n",
      "\tnode counts: max: 8, min: 5, mean: 5.83\n",
      " \tconn counts: max: 8, min: 0, mean: 4.06\n",
      " \tspecies: 10, [14, 23, 6, 21, 22, 14, 27, 11, 7, 105]\n",
      "\n",
      "Generation: 5, Cost time: 7548.70ms\n",
      " \tfitness: valid cnt: 250, max: 22.0969, min: -485.5624, mean: -38.7261, std: 73.5490\n",
      "\n",
      "\tnode counts: max: 8, min: 5, mean: 5.66\n",
      " \tconn counts: max: 8, min: 0, mean: 3.26\n",
      " \tspecies: 10, [25, 6, 27, 11, 25, 19, 13, 11, 9, 104]\n",
      "\n",
      "Generation: 6, Cost time: 7544.58ms\n",
      " \tfitness: valid cnt: 250, max: 72.9096, min: -416.7319, mean: -32.1031, std: 65.3138\n",
      "\n",
      "\tnode counts: max: 9, min: 5, mean: 5.38\n",
      " \tconn counts: max: 8, min: 0, mean: 2.38\n",
      " \tspecies: 10, [7, 35, 22, 18, 16, 8, 13, 15, 2, 114]\n",
      "\n",
      "Generation: 7, Cost time: 7534.13ms\n",
      " \tfitness: valid cnt: 250, max: 21.4751, min: -407.1219, mean: -31.0392, std: 65.9276\n",
      "\n",
      "\tnode counts: max: 7, min: 5, mean: 5.38\n",
      " \tconn counts: max: 7, min: 0, mean: 2.08\n",
      " \tspecies: 10, [5, 14, 9, 8, 44, 13, 19, 11, 10, 117]\n",
      "\n",
      "Generation: 8, Cost time: 7520.67ms\n",
      " \tfitness: valid cnt: 250, max: 38.3513, min: -375.4320, mean: -31.1242, std: 62.2200\n",
      "\n",
      "\tnode counts: max: 8, min: 5, mean: 5.36\n",
      " \tconn counts: max: 7, min: 0, mean: 1.97\n",
      " \tspecies: 10, [35, 3, 10, 16, 25, 3, 17, 31, 9, 101]\n",
      "\n",
      "Generation: 9, Cost time: 7525.61ms\n",
      " \tfitness: valid cnt: 250, max: 40.4732, min: -523.3948, mean: -23.7056, std: 65.4107\n",
      "\n",
      "\tnode counts: max: 9, min: 5, mean: 5.46\n",
      " \tconn counts: max: 6, min: 0, mean: 2.08\n",
      " \tspecies: 10, [5, 19, 29, 22, 11, 18, 11, 11, 2, 122]\n",
      "\n",
      "Generation: 10, Cost time: 7531.13ms\n",
      " \tfitness: valid cnt: 250, max: 64.4478, min: -393.7125, mean: -25.8089, std: 62.8361\n",
      "\n",
      "\tnode counts: max: 8, min: 5, mean: 5.34\n",
      " \tconn counts: max: 6, min: 0, mean: 1.84\n",
      " \tspecies: 10, [7, 32, 5, 23, 20, 5, 9, 12, 3, 134]\n",
      "\n",
      "Generation: 11, Cost time: 7536.41ms\n",
      " \tfitness: valid cnt: 250, max: 76.1336, min: -350.6360, mean: -23.8691, std: 56.6802\n",
      "\n",
      "\tnode counts: max: 8, min: 5, mean: 5.48\n",
      " \tconn counts: max: 6, min: 0, mean: 2.13\n",
      " \tspecies: 10, [24, 19, 7, 18, 11, 19, 16, 1, 9, 126]\n",
      "\n",
      "Generation: 12, Cost time: 7527.51ms\n",
      " \tfitness: valid cnt: 250, max: 93.9942, min: -315.8109, mean: -13.4677, std: 47.7967\n",
      "\n",
      "\tnode counts: max: 8, min: 5, mean: 5.34\n",
      " \tconn counts: max: 6, min: 0, mean: 1.98\n",
      " \tspecies: 10, [33, 24, 1, 21, 10, 17, 16, 11, 1, 116]\n",
      "\n",
      "Generation: 13, Cost time: 7530.96ms\n",
      " \tfitness: valid cnt: 250, max: 95.1057, min: -384.0840, mean: -16.6012, std: 66.4173\n",
      "\n",
      "\tnode counts: max: 7, min: 5, mean: 5.25\n",
      " \tconn counts: max: 7, min: 0, mean: 1.89\n",
      " \tspecies: 10, [31, 5, 42, 7, 15, 17, 19, 11, 1, 102]\n",
      "\n",
      "Generation: 14, Cost time: 7539.20ms\n",
      " \tfitness: valid cnt: 250, max: 96.9992, min: -423.7019, mean: -13.1041, std: 77.0222\n",
      "\n",
      "\tnode counts: max: 8, min: 5, mean: 5.41\n",
      " \tconn counts: max: 8, min: 0, mean: 2.11\n",
      " \tspecies: 10, [26, 1, 7, 2, 16, 18, 13, 11, 9, 147]\n",
      "\n",
      "Generation: 15, Cost time: 7541.43ms\n",
      " \tfitness: valid cnt: 250, max: 98.8576, min: -480.9229, mean: -12.5688, std: 68.9957\n",
      "\n",
      "\tnode counts: max: 9, min: 5, mean: 5.43\n",
      " \tconn counts: max: 9, min: 0, mean: 2.53\n",
      " \tspecies: 10, [30, 37, 16, 16, 12, 22, 13, 14, 6, 84]\n",
      "\n",
      "Generation: 16, Cost time: 7556.30ms\n",
      " \tfitness: valid cnt: 250, max: 99.0013, min: -475.7370, mean: -24.2432, std: 83.1751\n",
      "\n",
      "\tnode counts: max: 8, min: 5, mean: 5.46\n",
      " \tconn counts: max: 8, min: 0, mean: 2.39\n",
      " \tspecies: 10, [40, 16, 18, 4, 13, 5, 41, 6, 16, 91]\n",
      "\n",
      "Generation: 17, Cost time: 7526.04ms\n",
      " \tfitness: valid cnt: 250, max: 98.9267, min: -627.2357, mean: -23.1153, std: 100.5325\n",
      "\n",
      "\tnode counts: max: 8, min: 5, mean: 5.51\n",
      " \tconn counts: max: 6, min: 0, mean: 2.44\n",
      " \tspecies: 10, [23, 32, 12, 14, 18, 7, 10, 11, 6, 117]\n",
      "\n",
      "Generation: 18, Cost time: 7547.77ms\n",
      " \tfitness: valid cnt: 250, max: 99.2305, min: -481.1073, mean: -13.1197, std: 92.2205\n",
      "\n",
      "\tnode counts: max: 9, min: 5, mean: 5.59\n",
      " \tconn counts: max: 6, min: 0, mean: 2.72\n",
      " \tspecies: 10, [32, 36, 17, 19, 13, 10, 14, 15, 2, 92]\n",
      "\n",
      "Generation: 19, Cost time: 7568.31ms\n",
      " \tfitness: valid cnt: 250, max: 99.4669, min: -434.7159, mean: 0.2177, std: 93.1178\n",
      "\n",
      "\tnode counts: max: 9, min: 5, mean: 5.52\n",
      " \tconn counts: max: 6, min: 0, mean: 2.67\n",
      " \tspecies: 10, [30, 25, 38, 17, 16, 6, 5, 7, 13, 93]\n",
      "\n",
      "Generation: 20, Cost time: 7568.49ms\n",
      " \tfitness: valid cnt: 250, max: 99.7292, min: -509.4752, mean: -5.4369, std: 100.8158\n",
      "\n",
      "\tnode counts: max: 9, min: 5, mean: 5.50\n",
      " \tconn counts: max: 5, min: 0, mean: 2.84\n",
      " \tspecies: 10, [15, 33, 37, 21, 18, 9, 7, 15, 9, 86]\n",
      "\n",
      "Generation: 21, Cost time: 7557.77ms\n",
      " \tfitness: valid cnt: 250, max: 130.8331, min: -525.3611, mean: -8.8419, std: 110.5919\n",
      "\n",
      "\tnode counts: max: 9, min: 5, mean: 5.50\n",
      " \tconn counts: max: 7, min: 0, mean: 2.95\n",
      " \tspecies: 10, [31, 32, 21, 27, 17, 7, 25, 16, 2, 72]\n",
      "\n",
      "Generation: 22, Cost time: 7568.54ms\n",
      " \tfitness: valid cnt: 250, max: 100.1653, min: -358.0607, mean: -6.9773, std: 95.6292\n",
      "\n",
      "\tnode counts: max: 9, min: 5, mean: 5.69\n",
      " \tconn counts: max: 7, min: 1, mean: 3.29\n",
      " \tspecies: 10, [36, 33, 22, 7, 2, 8, 30, 17, 3, 92]\n",
      "\n",
      "Generation: 23, Cost time: 7499.14ms\n",
      " \tfitness: valid cnt: 250, max: 110.6232, min: -561.4257, mean: -16.3062, std: 119.5345\n",
      "\n",
      "\tnode counts: max: 9, min: 5, mean: 5.92\n",
      " \tconn counts: max: 8, min: 1, mean: 3.67\n",
      " \tspecies: 10, [1, 21, 23, 22, 21, 31, 16, 7, 8, 100]\n",
      "\n",
      "Generation: 24, Cost time: 7464.30ms\n",
      " \tfitness: valid cnt: 250, max: 99.4125, min: -472.9791, mean: -18.2570, std: 115.1312\n",
      "\n",
      "\tnode counts: max: 9, min: 5, mean: 5.97\n",
      " \tconn counts: max: 9, min: 0, mean: 3.95\n",
      " \tspecies: 10, [10, 29, 18, 17, 24, 20, 7, 7, 3, 115]\n",
      "\n",
      "Generation: 25, Cost time: 7406.07ms\n",
      " \tfitness: valid cnt: 250, max: 110.0553, min: -487.8342, mean: -22.6480, std: 121.7014\n",
      "\n",
      "\tnode counts: max: 9, min: 5, mean: 5.87\n",
      " \tconn counts: max: 9, min: 0, mean: 3.69\n",
      " \tspecies: 10, [2, 19, 24, 21, 25, 22, 19, 11, 2, 105]\n",
      "\n",
      "Generation: 26, Cost time: 7238.95ms\n",
      " \tfitness: valid cnt: 250, max: 105.0953, min: -557.4125, mean: 2.2408, std: 105.1194\n",
      "\n",
      "\tnode counts: max: 9, min: 5, mean: 6.08\n",
      " \tconn counts: max: 8, min: 1, mean: 3.90\n",
      " \tspecies: 10, [2, 21, 24, 22, 18, 6, 20, 15, 1, 121]\n",
      "\n",
      "Generation: 27, Cost time: 7295.22ms\n",
      " \tfitness: valid cnt: 250, max: 99.8915, min: -502.6453, mean: -2.8883, std: 115.8256\n",
      "\n",
      "\tnode counts: max: 9, min: 5, mean: 6.05\n",
      " \tconn counts: max: 9, min: 0, mean: 3.73\n",
      " \tspecies: 10, [15, 1, 23, 33, 35, 3, 31, 1, 2, 106]\n",
      "\n",
      "Generation: 28, Cost time: 7335.52ms\n",
      " \tfitness: valid cnt: 250, max: 100.4969, min: -580.0872, mean: 1.5705, std: 109.3527\n",
      "\n",
      "\tnode counts: max: 9, min: 5, mean: 6.09\n",
      " \tconn counts: max: 9, min: 1, mean: 3.61\n",
      " \tspecies: 10, [60, 3, 18, 19, 20, 9, 18, 4, 4, 95]\n",
      "\n",
      "Generation: 29, Cost time: 7280.07ms\n",
      " \tfitness: valid cnt: 250, max: 101.0610, min: -390.5451, mean: 11.4878, std: 94.1255\n",
      "\n",
      "\tnode counts: max: 10, min: 5, mean: 6.18\n",
      " \tconn counts: max: 9, min: 1, mean: 3.58\n",
      " \tspecies: 10, [57, 36, 2, 12, 12, 10, 15, 6, 7, 93]\n",
      "\n",
      "Generation: 30, Cost time: 7343.91ms\n",
      " \tfitness: valid cnt: 250, max: 101.6156, min: -584.6234, mean: 6.7892, std: 116.3159\n",
      "\n",
      "\tnode counts: max: 10, min: 5, mean: 6.02\n",
      " \tconn counts: max: 10, min: 1, mean: 3.62\n",
      " \tspecies: 10, [38, 22, 2, 12, 18, 8, 17, 22, 4, 107]\n",
      "\n",
      "Generation limit reached!\n",
      "--> Step 1 Finished: Expert agent has been trained.\n",
      "--> Step 2: Collecting 10000 data points using the expert policy...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-02 20:06:45.371837: W external/xla/xla/service/gpu/autotuning/dot_search_space.cc:200] All configs were filtered out because none of them sufficiently match the hints. Maybe the hints set does not contain a good representative set of valid configs?Working around this by using the full hints set instead.\n",
      "2025-09-02 20:06:45.371856: W external/xla/xla/service/gpu/autotuning/dot_search_space.cc:200] All configs were filtered out because none of them sufficiently match the hints. Maybe the hints set does not contain a good representative set of valid configs?Working around this by using the full hints set instead.\n",
      "2025-09-02 20:06:45.371862: W external/xla/xla/service/gpu/autotuning/dot_search_space.cc:200] All configs were filtered out because none of them sufficiently match the hints. Maybe the hints set does not contain a good representative set of valid configs?Working around this by using the full hints set instead.\n",
      "2025-09-02 20:06:45.371866: W external/xla/xla/service/gpu/autotuning/dot_search_space.cc:200] All configs were filtered out because none of them sufficiently match the hints. Maybe the hints set does not contain a good representative set of valid configs?Working around this by using the full hints set instead.\n",
      "2025-09-02 20:06:45.371871: W external/xla/xla/service/gpu/autotuning/dot_search_space.cc:200] All configs were filtered out because none of them sufficiently match the hints. Maybe the hints set does not contain a good representative set of valid configs?Working around this by using the full hints set instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Expert Training and Data Collection Finished ---\n",
      "\n",
      "Starting data collection for 10000 steps using a random policy...\n",
      "Random data collection finished.\n"
     ]
    }
   ],
   "source": [
    "SAMPLING_STEPS = 10000\n",
    "key = jax.random.PRNGKey(123) # A key for all sampling operations\n",
    "\n",
    "# --- Method A: Collect data by training and running an expert ---\n",
    "key, expert_key = jax.random.split(key)\n",
    "expert_data = collect_expert_policy_data(\n",
    "    env_problem=env_problem,\n",
    "    key=expert_key,\n",
    "    num_steps=SAMPLING_STEPS,\n",
    "    training_config=expert_sample_config  # Pass the config dictionary\n",
    ")\n",
    "\n",
    "# --- Method B: Collect random data ---\n",
    "key, random_key = jax.random.split(key)\n",
    "random_data = collect_random_policy_data(env_problem, random_key, SAMPLING_STEPS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e04e5df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Analyzing Expert Data ---\n",
      "Running PCA to find dimensions covering 90.0% of variance (with a hard limit of 10 dimensions)...\n",
      "PCA found 12 dimensions are needed for 90.0% variance.\n",
      "Applying max limit. Final number of dimensions: 10\n",
      "PCA variance plot saved to: output/ant/pca_variance_expert.png\n",
      "\n",
      "--- Analyzing Random Data ---\n",
      "Running PCA to find dimensions covering 90.0% of variance (with a hard limit of 10 dimensions)...\n",
      "PCA found 29 dimensions are needed for 90.0% variance.\n",
      "Applying max limit. Final number of dimensions: 10\n",
      "PCA variance plot saved to: output/ant/pca_variance_random.png\n",
      "\n",
      "--- Comparison Finished ---\n",
      "Dimensions from Expert Data: 10\n",
      "Dimensions from Random Data: 10\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# --- Step 2: Analyze and visualize both datasets ---\n",
    "VARIANCE_THRESHOLD = 0.75\n",
    "MAX_PCA_DIMS = 10\n",
    "\n",
    "# --- Analysis A: PCA on Expert Data ---\n",
    "print(\"\\n--- Analyzing Expert Data ---\")\n",
    "analyzer_expert = PCAanalyzer(\n",
    "    data=expert_data, obs_size=obs_size, act_size=act_size,\n",
    "    variance_threshold=VARIANCE_THRESHOLD, max_dims=MAX_PCA_DIMS\n",
    ")\n",
    "input_coors_exp, output_coors_exp, coord_size_exp = analyzer_expert.generate_input_coordinates()\n",
    "analyzer_expert.plot_variance(save_path=f\"{OUTPUT_DIR}/pca_variance_expert.png\")\n",
    "\n",
    "# --- Analysis B: PCA on Random Data ---\n",
    "print(\"\\n--- Analyzing Random Data ---\")\n",
    "analyzer_random = PCAanalyzer(\n",
    "    data=random_data, obs_size=obs_size, act_size=act_size,\n",
    "    variance_threshold=VARIANCE_THRESHOLD, max_dims=MAX_PCA_DIMS\n",
    ")\n",
    "input_coors_rand, output_coors_rand, coord_size_rand = analyzer_random.generate_input_coordinates()\n",
    "analyzer_random.plot_variance(save_path=f\"{OUTPUT_DIR}/pca_variance_random.png\")\n",
    "\n",
    "\n",
    "print(\"\\n--- Comparison Finished ---\")\n",
    "print(f\"Dimensions from Expert Data: {coord_size_exp}\")\n",
    "print(f\"Dimensions from Random Data: {coord_size_rand}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "37dd80a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating hidden coordinates for the 'expert' substrate...\n",
      "Creating the FullSubstrate...\n",
      "Substrate created successfully.\n",
      "Number of input neurons: 27\n",
      "input_coors:  [(-0.006685928, -0.3723647, 0.025974808, 0.20740637, 0.02408069, -0.032099, 0.08049005, -0.011359929, 0.12699984, -0.028929625), (-0.00564604, 0.039012503, 0.08518723, 0.11163324, 0.06815545, -0.058911033, 0.051043317, 0.91495556, -0.13343035, -0.22755793), (-0.010348022, 0.14151213, 0.38181785, 0.24739674, 0.04306853, 0.077444986, -0.10280492, -0.08404915, 0.14361846, 0.012987032), (0.0046063885, -0.19662297, 0.24887682, -0.07785269, -0.20216848, 0.47169673, -0.09007876, 0.06041028, 0.06486236, -0.19225366), (-0.0020541383, 0.14341721, -0.21130061, -0.107435115, 0.34480336, 0.115032814, 0.056150425, 0.10759093, 0.57400095, -0.084230915), (0.0029763961, -0.23372509, -0.023099387, -0.14733346, -0.3667739, 0.14132462, -0.1015876, -0.0808644, -0.20319968, -0.091210276), (-0.011504292, -0.2644248, 0.030848473, 0.28540742, 0.15618171, -0.25575033, 0.075279124, -0.062085833, 0.2475414, 0.072590604), (0.0048166383, -0.30109203, -0.14713201, -0.09100854, -0.2114762, -0.015242283, 0.10045967, 0.033318914, -0.009716218, -0.12458277), (0.0079264715, 0.28479964, -0.2478704, -0.26657236, -0.029498702, -0.120640665, -0.01065097, 0.03781917, -0.19279619, 0.06309603), (-0.0004743212, -0.30564052, -0.15662077, -0.1394034, -0.0726345, 0.000994899, -0.050545108, 0.07852255, 0.034183763, -0.023947276), (-0.0019203529, 0.38067976, -0.07325246, -0.08827733, 0.07090356, -0.10917758, -0.03974752, -0.011073247, -0.046343844, 0.026489306), (-0.006335267, 0.04387976, 0.3967621, 0.3371098, -0.043919865, -0.027074361, 0.020848036, 0.016510969, -0.079948045, 0.049101487), (-0.0021913734, -0.30447227, -0.22362682, 0.15924872, 0.12363698, -0.16306356, 0.2261062, 0.06949208, 0.023858882, 0.01595244), (-0.04334866, 0.008545728, -0.09153641, -0.071306385, 0.2563552, 0.6148983, 0.1789617, -0.02194216, 0.16340847, -0.11448698), (-0.067600764, -0.20921537, -0.3742424, -0.043332122, 0.12759759, -0.024467636, -0.1691553, 0.032327656, -0.08899156, 0.02465118), (0.068065315, 0.11695917, -0.2512877, 0.35717696, -0.08148966, 0.16413361, -0.023520479, -0.02015429, -0.0946439, 0.04086071), (0.014513893, -0.019071057, 0.2111573, -0.23720111, 0.22019261, -0.042258356, 0.5157517, -0.14224131, -0.25673002, -0.3305213), (0.200302, -0.0626858, 0.06526849, -0.02919089, 0.24915107, 0.03746952, 0.19950773, -0.13989043, -0.10934194, 0.1265747), (0.20028453, -0.040562373, 0.06483234, -0.1481373, 0.014961933, 0.23644356, 0.18753459, 0.20027748, -0.088784926, 0.5011101), (-0.090364985, -0.14189789, 0.098490566, 0.03692865, 0.4147347, 0.09958614, -0.32226416, -0.033460535, -0.22226639, 0.07734762), (-0.15796386, 0.13961159, -0.17533536, 0.24924941, 0.0012006764, 0.19664527, -0.016084967, -0.026999114, -0.23323497, -0.15435992), (-0.25059703, 0.055237927, -0.05679614, 0.06749525, 0.024222141, -0.0037410248, -0.14261824, -0.076171, 0.09385288, -0.18346375), (-0.19016124, -0.03134466, 0.122268975, -0.22372016, -0.103647396, -0.044735212, -0.3198776, 0.11839068, 0.30644014, 0.1721664), (-0.20913558, -0.0027879686, -0.030238273, 0.06335742, 0.16109006, -0.11920821, -0.12759754, -0.10275204, -0.108935855, -0.43098956), (-0.18903542, -0.017440008, 0.1759614, -0.2844824, -0.002012346, -0.025639273, -0.098796435, 0.000613179, 0.050111692, -0.22151697), (0.15046598, 0.14785665, 0.016976116, -0.014488622, -0.3472595, -0.1670332, 0.29696065, -0.02823094, 0.3315803, -0.21232952), (-0.019245517, 0.14785366, -0.24811403, 0.31632265, -0.24924585, 0.23651172, 0.092778176, -0.017301654, 0.029674258, -0.05205776)]\n",
      "Number of hidden neurons: 64\n",
      "Number of output neurons: 8\n"
     ]
    }
   ],
   "source": [
    "print(\"Generating hidden coordinates for the 'expert' substrate...\")\n",
    "\n",
    "# (You might need to re-instantiate this if it's not in the same cell)\n",
    "substrate_gen = SubstrateGenerator(\n",
    "    env_name=ENV_NAME,\n",
    "    obs_size=obs_size,\n",
    "    act_size=act_size,\n",
    "    hidden_layer_type=HIDDEN_LAYER_TYPE,\n",
    "    hidden_depth=HIDDEN_DEPTH,\n",
    ")\n",
    "\n",
    "hidden_coors_exp = substrate_gen.get_hidden_coors(\n",
    "    input_coors=input_coors_exp, \n",
    "    coord_size=coord_size_exp\n",
    ")\n",
    "\n",
    "\n",
    "# 2. Now, create the substrate with the correct variables in the correct places.\n",
    "print(\"Creating the FullSubstrate...\")\n",
    "active_substrate = FullSubstrate(\n",
    "    input_coors=input_coors_exp,      # Coordinates for input layer\n",
    "    hidden_coors=hidden_coors_exp,    # Correctly use the newly generated hidden coordinates\n",
    "    output_coors=output_coors_exp     # Correctly use the output coordinates list, not the size integer\n",
    ")\n",
    "\n",
    "print(\"Substrate created successfully.\")\n",
    "print(f\"Number of input neurons: {len(input_coors_exp)}\")\n",
    "print(\"input_coors: \", input_coors_exp)\n",
    "print(f\"Number of hidden neurons: {len(hidden_coors_exp)}\")\n",
    "print(f\"Number of output neurons: {len(output_coors_exp)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c2a9abc1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "query_coors shape: (6336, 20)\n",
      "That means 10 dimensions with 2 query nodes each.\n"
     ]
    }
   ],
   "source": [
    "print(\"query_coors shape:\", active_substrate.query_coors.shape)  # (num_queries, query_dim)\n",
    "query_dim = int(active_substrate.query_coors.shape[1])\n",
    "print(f\"That means {int(query_dim/2)} dimensions with 2 query nodes each.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9693d0ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "conn_gene = DefaultConn(\n",
    "    weight_mutate_power=0.25,\n",
    "    weight_mutate_rate=0.3,\n",
    "    weight_lower_bound=-1.0,\n",
    "    weight_upper_bound=1.0,\n",
    ")\n",
    "\n",
    "genome=DefaultGenome(\n",
    "    num_inputs=query_dim,\n",
    "    num_outputs=1,\n",
    "    output_transform=ACT.tanh,\n",
    "    max_nodes=256,\n",
    "    max_conns=1024,\n",
    "    init_hidden_layers=[int(query_dim/4)],\n",
    "    mutation=DefaultMutation(\n",
    "        node_add=0.4,\n",
    "        conn_add=0.5, \n",
    "        node_delete=0.15,\n",
    "        conn_delete=0.2,\n",
    "    ),\n",
    "    conn_gene=conn_gene,\n",
    ")\n",
    "\n",
    "neat_algorithm = NEAT(\n",
    "    pop_size=POP_SIZE,\n",
    "    species_size=SPECIES_SIZE,\n",
    "    survival_threshold=0.10,\n",
    "    compatibility_threshold=1.0,\n",
    "    species_fitness_func=jnp.mean, # alternative jnp.mean / jnp.max,\n",
    "    genome_elitism=5,\n",
    "    species_elitism=3,\n",
    "    genome=genome,\n",
    ")\n",
    "\n",
    "evol_algorithm = HyperNEAT(\n",
    "    substrate=active_substrate,\n",
    "    neat=neat_algorithm,\n",
    "    activation=ACT.tanh,\n",
    "    activate_time=25, # How many internal activation steps per simulation step (recurrence)\n",
    "    output_transform=ACT.tanh,\n",
    "    weight_threshold=WEIGHT_TRESHOLD,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0217f420",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total observation shape: (27,)\n",
      "Total action shape: (8,)\n",
      "Substrate input dimension: 20\n",
      "Algorithm input dimension: 26\n"
     ]
    }
   ],
   "source": [
    "print(\"Total observation shape:\", env_problem.input_shape)\n",
    "print(\"Total action shape:\", env_problem.output_shape)\n",
    "\n",
    "print(\"Substrate input dimension:\", active_substrate.query_coors.shape[1])\n",
    "print(\"Algorithm input dimension:\", evol_algorithm.num_inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3fc62792",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mwirkelzirkel\u001b[0m (\u001b[33mwirkelzirkel-iu\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.21.1"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/andi/Dokumente/Bachelorarbeit/dim_tuning/wandb/run-20250902_202010-fzopumis</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/wirkelzirkel-iu/connection_cost/runs/fzopumis' target=\"_blank\">ant_man</a></strong> to <a href='https://wandb.ai/wirkelzirkel-iu/connection_cost' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/wirkelzirkel-iu/connection_cost' target=\"_blank\">https://wandb.ai/wirkelzirkel-iu/connection_cost</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/wirkelzirkel-iu/connection_cost/runs/fzopumis' target=\"_blank\">https://wandb.ai/wirkelzirkel-iu/connection_cost/runs/fzopumis</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src='https://wandb.ai/wirkelzirkel-iu/connection_cost/runs/fzopumis?jupyter=true' style='border:none;width:100%;height:420px;display:none;'></iframe>"
      ],
      "text/plain": [
       "<wandb.sdk.wandb_run.Run at 0x764468415ab0>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wanbd_name = f\"{ENV_NAME}_{WANDB_NAME_SUFFIX}\" if WANDB_NAME_SUFFIX != \"\" else ENV_NAME\n",
    "WANDB_TAGS = [HIDDEN_LAYER_TYPE, ENV_NAME]\n",
    "\n",
    "wandb.init(name=wanbd_name, project=\"connection_cost\", tags=WANDB_TAGS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5e5221b9",
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "algorithm input shape is 26 but problem input shape is (27,)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m pipeline \u001b[38;5;241m=\u001b[39m \u001b[43mCustomPipeline\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43m    \u001b[49m\u001b[43malgorithm\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mevol_algorithm\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[43mproblem\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43menv_problem\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43mseed\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m42\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgeneration_limit\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mGENERATION_LIMIT\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfitness_target\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mFITNESS_TARGET\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_save\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m    \u001b[49m\u001b[43msave_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mOUTPUT_DIR\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Dokumente/Bachelorarbeit/dim_tuning/custom_pipeline.py:40\u001b[0m, in \u001b[0;36mCustomPipeline.__init__\u001b[0;34m(self, algorithm, problem, seed, fitness_target, generation_limit, is_save, save_dir, show_problem_details, using_multidevice)\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpop_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39malgorithm\u001b[38;5;241m.\u001b[39mpop_size\n\u001b[1;32m     37\u001b[0m np\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39mseed(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mseed)\n\u001b[1;32m     39\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m (\n\u001b[0;32m---> 40\u001b[0m     algorithm\u001b[38;5;241m.\u001b[39mnum_inputs \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mproblem\u001b[38;5;241m.\u001b[39minput_shape[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m     41\u001b[0m ), \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124malgorithm input shape is \u001b[39m\u001b[38;5;132;01m{\u001b[39;00malgorithm\u001b[38;5;241m.\u001b[39mnum_inputs\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m but problem input shape is \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mproblem\u001b[38;5;241m.\u001b[39minput_shape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     43\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbest_genome \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     44\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbest_fitness \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mfloat\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m-inf\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mAssertionError\u001b[0m: algorithm input shape is 26 but problem input shape is (27,)"
     ]
    }
   ],
   "source": [
    "pipeline = CustomPipeline(\n",
    "    algorithm=evol_algorithm,\n",
    "    problem=env_problem,\n",
    "    seed=42,\n",
    "    generation_limit=GENERATION_LIMIT,\n",
    "    fitness_target=FITNESS_TARGET,\n",
    "    is_save=False,\n",
    "    save_dir=OUTPUT_DIR,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d316ddbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "init_state = pipeline.setup()\n",
    "state = pipeline.auto_run(\n",
    "    state=init_state\n",
    ")\n",
    "\n",
    "print(f\"\\nTraining finished. Best fitness achieved: {pipeline.best_fitness}\")\n",
    "\n",
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7ac61df",
   "metadata": {},
   "outputs": [],
   "source": [
    "state_for_show = state[0] if isinstance(state, tuple) else state\n",
    "\n",
    "# Transform the best genome into network parameters\n",
    "best_genome = pipeline.best_genome\n",
    "\n",
    "# Use the built-in show method to visualize and save video\n",
    "pipeline.show(\n",
    "    state=state_for_show,\n",
    "    best=best_genome,\n",
    "    output_type=\"mp4\",\n",
    "    save_path=f\"{OUTPUT_DIR}/agent.mp4\",\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4339fa64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize cppn\n",
    "cppn_genome = pipeline.algorithm.neat.genome\n",
    "cppn_network = cppn_genome.network_dict(state, *best_genome)\n",
    "cppn_genome.visualize(cppn_network, save_path=f\"{OUTPUT_DIR}/cppn_network.svg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff16c13d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "from matplotlib.colors import Normalize\n",
    "from matplotlib.cm import ScalarMappable\n",
    "\n",
    "print(\"Manually reconstructing the phenotype. A visual layout will be generated.\")\n",
    "\n",
    "# 1) Weights from CPPN (your existing logic)\n",
    "neat_algorithm = pipeline.algorithm.neat\n",
    "cppn_params = neat_algorithm.transform(state, best_genome)\n",
    "query_coors = active_substrate.query_coors\n",
    "cppn_forward_func = neat_algorithm.forward\n",
    "\n",
    "all_substrate_weights = jax.vmap(\n",
    "    cppn_forward_func, in_axes=(None, None, 0)\n",
    ")(state, cppn_params, query_coors)\n",
    "\n",
    "all_substrate_connections = np.array(active_substrate.conns)\n",
    "all_substrate_weights_np = np.array(all_substrate_weights).squeeze()\n",
    "\n",
    "# 2) Select edges: no percentile pruning; keep internal threshold (toggleable)\n",
    "internal_weight_threshold = pipeline.algorithm.weight_threshold\n",
    "active_mask = np.abs(all_substrate_weights_np) > internal_weight_threshold\n",
    "active_conns = all_substrate_connections[active_mask]\n",
    "active_weights = all_substrate_weights_np[active_mask]\n",
    "\n",
    "# If you want literally every potential connection regardless of threshold:\n",
    "# active_conns = all_substrate_connections\n",
    "# active_weights = all_substrate_weights_np\n",
    "\n",
    "print(f\"Substrate has {len(all_substrate_connections)} potential connections.\")\n",
    "\n",
    "# Build graph, assign layers, generate layout\n",
    "G_to_draw = nx.DiGraph()\n",
    "all_node_keys = [int(n[0]) for n in active_substrate.nodes]\n",
    "\n",
    "\n",
    "# Which coordinate dimension encodes \"layer\"? In your code it's the last one.\n",
    "LAYER_AXIS = -1  # last coordinate\n",
    "\n",
    "def compute_hidden_layer_groups(hidden_coors, layer_axis=LAYER_AXIS):\n",
    "    \"\"\"\n",
    "    Returns:\n",
    "    order_vals: sorted unique layer values (e.g., 3, 6, 9, ...)\n",
    "    idx_groups: list of lists; each inner list has indices of hidden nodes that belong to that layer\n",
    "    widths:     number of hidden nodes per layer (len of each group)\n",
    "    \"\"\"\n",
    "    hc = np.asarray(hidden_coors)\n",
    "    if hc.ndim != 2:\n",
    "        raise ValueError(f\"hidden_coors must be 2D (num_hidden, coord_dims); got shape {hc.shape}\")\n",
    "\n",
    "    layer_vals = hc[:, layer_axis]\n",
    "    order_vals = np.unique(layer_vals)\n",
    "    idx_groups = [np.where(layer_vals == v)[0].tolist() for v in order_vals]\n",
    "    widths = [len(g) for g in idx_groups]\n",
    "    return order_vals.tolist(), idx_groups, widths\n",
    "\n",
    "# Example usage:\n",
    "order_vals, hidden_idx_groups, hidden_widths = compute_hidden_layer_groups(hidden_coors, layer_axis=LAYER_AXIS)\n",
    "# All node keys in substrate order (N,1) -> flatten to ints\n",
    "all_node_keys = [int(n[0]) for n in active_substrate.nodes]\n",
    "\n",
    "num_inputs  = len(input_coors)\n",
    "num_outputs = len(output_coors)\n",
    "num_hiddens = len(hidden_coors)\n",
    "\n",
    "# Correct slicing for FullSubstrate:\n",
    "input_keys  = all_node_keys[:num_inputs]\n",
    "output_keys = all_node_keys[num_inputs : num_inputs + num_outputs]\n",
    "hidden_keys = all_node_keys[num_inputs + num_outputs : num_inputs + num_outputs + num_hiddens]\n",
    "\n",
    "# Add nodes to the graph with subsets (partitions) for visualization\n",
    "G_to_draw = nx.DiGraph()\n",
    "\n",
    "# Inputs at layer 0\n",
    "for k in input_keys:\n",
    "    G_to_draw.add_node(k, subset=0)\n",
    "\n",
    "# Hidden layers (1..HIDDEN_DEPTH) — we map the *contiguous* hidden range to layers\n",
    "start_hidden = num_inputs + num_outputs\n",
    "\n",
    "# If each hidden layer has the same width (classic case):\n",
    "# hidden_width_full = len(input_coors)  # or len(hidden_coors)//HIDDEN_DEPTH\n",
    "# But we will use the robust per-layer widths we computed above:\n",
    "cum = 0\n",
    "for j, w in enumerate(hidden_widths):\n",
    "    layer_id = j + 1\n",
    "    start = start_hidden + cum\n",
    "    end   = start + w\n",
    "    for i in range(start, min(end, len(all_node_keys))):\n",
    "        G_to_draw.add_node(all_node_keys[i], subset=layer_id)\n",
    "    cum += w\n",
    "\n",
    "# Outputs at the final layer (after all hidden layers)\n",
    "output_layer_id = HIDDEN_DEPTH + 1\n",
    "for k in output_keys:\n",
    "    G_to_draw.add_node(k, subset=output_layer_id)\n",
    "\n",
    "\n",
    "# Layout from the detailed layer assignment\n",
    "pos = nx.multipartite_layout(G_to_draw, subset_key='subset')\n",
    "\n",
    "# 4) Fixed-bounds grayscale mapping & robust edge extraction\n",
    "\n",
    "# Helper: coerce bounds to floats (in case 0,0 was typed instead of 0.0)\n",
    "def _to_float_bound(x, name):\n",
    "    if isinstance(x, (tuple, list, np.ndarray)):\n",
    "        if len(x) == 0:\n",
    "            raise ValueError(f\"{name} is empty; set a valid float (e.g., 0.0).\")\n",
    "        x = x[0]\n",
    "    try:\n",
    "        return float(x)\n",
    "    except Exception as e:\n",
    "        raise ValueError(\n",
    "            f\"Could not convert {name}={x!r} to float. \"\n",
    "            f\"Use a scalar like 0.0 or 1.0. Original error: {e}\"\n",
    "        )\n",
    "\n",
    "LOWER = _to_float_bound(WEIGHT_LOWER_BOUND, \"WEIGHT_LOWER_BOUND\")\n",
    "UPPER = _to_float_bound(WEIGHT_UPPER_BOUND, \"WEIGHT_UPPER_BOUND\")\n",
    "\n",
    "# Your active_conns rows look like [src, dst, extra]; take first two columns\n",
    "ac = np.asarray(active_conns)\n",
    "if ac.ndim != 2 or ac.shape[1] < 2:\n",
    "    raise ValueError(f\"Expected active_conns to have at least 2 columns; got shape {ac.shape}\")\n",
    "\n",
    "all_edges = [(int(row[0]), int(row[1])) for row in ac]\n",
    "all_weights = np.asarray(active_weights)\n",
    "\n",
    "# NEW: Filter out self-loops\n",
    "# Create lists to hold the edges and weights that are NOT self-loops\n",
    "edges_to_add = []\n",
    "active_weights_filtered = []\n",
    "for edge, weight in zip(all_edges, all_weights):\n",
    "    if edge[0] != edge[1]:  # This condition checks if the edge is NOT a self-loop\n",
    "        edges_to_add.append(edge)\n",
    "        active_weights_filtered.append(weight)\n",
    "\n",
    "# Convert back to a NumPy array for consistency\n",
    "active_weights = np.array(active_weights_filtered)\n",
    "\n",
    "print(f\"Visualizing {len(active_weights)} connections. Excluded loops. Weight threshold: {internal_weight_threshold}\")\n",
    "\n",
    "# Add edges to graph\n",
    "G_to_draw.add_edges_from(edges_to_add)\n",
    "\n",
    "# Magnitudes for color mapping (must align 1:1 with edges_to_add)\n",
    "abs_w = np.abs(active_weights)\n",
    "if len(abs_w) != len(edges_to_add):\n",
    "    raise ValueError(\n",
    "        f\"Edge/weight mismatch: {len(edges_to_add)} edges vs {len(abs_w)} weights. \"\n",
    "        \"Ensure any filtering is applied identically to connections and weights.\"\n",
    "    )\n",
    "\n",
    "# Edge-width scaling (optional) using fixed bounds in [0,1]\n",
    "if abs_w.size > 0:\n",
    "    norm_for_widths = np.clip((abs_w - LOWER) / (UPPER - LOWER), 0.0, 1.0)\n",
    "else:\n",
    "    norm_for_widths = np.array([], dtype=float)\n",
    "\n",
    "# Node colors: inputs=blue, outputs=red, hidden=green\n",
    "node_colors = []\n",
    "for node_key in G_to_draw.nodes():\n",
    "    if node_key in input_keys:\n",
    "        color = 'blue'\n",
    "    elif node_key in output_keys:\n",
    "        color = 'red'\n",
    "    else:\n",
    "        color = 'green'\n",
    "    node_colors.append(color)\n",
    "\n",
    "# 5) Draw with separate colormaps for positive (Greys) and negative (Reds)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(12, 12))\n",
    "\n",
    "weights = np.asarray(active_weights)\n",
    "idx_all = np.arange(len(edges_to_add))\n",
    "\n",
    "pos_idx = idx_all[weights > 0]\n",
    "neg_idx = idx_all[weights < 0]\n",
    "zero_idx = idx_all[weights == 0]  # optional\n",
    "\n",
    "edges_pos = [edges_to_add[i] for i in pos_idx]\n",
    "edges_neg = [edges_to_add[i] for i in neg_idx]\n",
    "w_pos = weights[pos_idx]                # > 0\n",
    "w_neg_mag = -weights[neg_idx]           # positive magnitudes for negative edges\n",
    "\n",
    "# Edge widths scaled per side using fixed bounds\n",
    "eps = np.finfo(float).eps  # protect against division by zero\n",
    "\n",
    "widths_pos = 0.5 + 1.5 * np.clip(w_pos / max(UPPER, eps), 0.0, 1.0) if len(w_pos) else []\n",
    "widths_neg = 0.5 + 1.5 * np.clip(w_neg_mag / max(-LOWER, eps), 0.0, 1.0) if len(w_neg_mag) else []\n",
    "\n",
    "# Draw nodes once\n",
    "nx.draw_networkx_nodes(\n",
    "    G_to_draw,\n",
    "    pos=pos,\n",
    "    node_color=node_colors,\n",
    "    node_size=20,\n",
    "    ax=ax\n",
    ")\n",
    "\n",
    "# Draw POSITIVE edges: Greys (white → black), mapped over [0, UPPER]\n",
    "if len(edges_pos):\n",
    "    nx.draw_networkx_edges(\n",
    "        G_to_draw,\n",
    "        pos=pos,\n",
    "        edgelist=edges_pos,\n",
    "        edge_color=w_pos,             # raw positive weights\n",
    "        edge_cmap=plt.cm.Greys,\n",
    "        edge_vmin=0.0,\n",
    "        edge_vmax=float(UPPER),\n",
    "        width=widths_pos,\n",
    "        arrows=True,\n",
    "        arrowstyle='-|>',\n",
    "        arrowsize=4,\n",
    "        ax=ax\n",
    "    )\n",
    "\n",
    "# Draw NEGATIVE edges: Reds (white → red), mapped over [0, |LOWER|] using magnitudes\n",
    "if len(edges_neg):\n",
    "    nx.draw_networkx_edges(\n",
    "        G_to_draw,\n",
    "        pos=pos,\n",
    "        edgelist=edges_neg,\n",
    "        edge_color=w_neg_mag,         # magnitudes of negative weights\n",
    "        edge_cmap=plt.cm.Reds,\n",
    "        edge_vmin=0.0,\n",
    "        edge_vmax=float(-LOWER),\n",
    "        width=widths_neg,\n",
    "        arrows=True,\n",
    "        arrowstyle='-|>',\n",
    "        arrowsize=4,\n",
    "        ax=ax\n",
    "    )\n",
    "\n",
    "# Colorbars\n",
    "from matplotlib.colors import Normalize\n",
    "from matplotlib.cm import ScalarMappable\n",
    "from mpl_toolkits.axes_grid1.inset_locator import inset_axes\n",
    "\n",
    "ax.set_title(f\"Substrate Network — Positives Greys, Negatives Reds (Bounds [{LOWER}, {UPPER}])\")\n",
    "fig.tight_layout()\n",
    "fig.subplots_adjust(bottom=0.18) # Manually make space at the bottom for colorbars\n",
    "\n",
    "# Left: negative (Reds)\n",
    "if len(w_neg_mag):\n",
    "    sm_neg = ScalarMappable(cmap=plt.cm.Reds,\n",
    "                            norm=Normalize(vmin=0.0, vmax=float(-LOWER)))\n",
    "    sm_neg.set_array([])\n",
    "    cax_neg = inset_axes(\n",
    "        ax, width=\"32%\", height=\"3%\", loc=\"lower left\",\n",
    "        bbox_to_anchor=(0.06, -0.12, 1.0, 1.0),  # left aligned\n",
    "        bbox_transform=ax.transAxes, borderpad=0\n",
    "    )\n",
    "    cbar_neg = fig.colorbar(sm_neg, cax=cax_neg, orientation='horizontal')\n",
    "    cbar_neg.set_label('Negative |weight|', labelpad=2)\n",
    "    cbar_neg.ax.xaxis.set_label_position('bottom')\n",
    "    cbar_neg.ax.xaxis.set_ticks_position('bottom')\n",
    "    cbar_neg.set_ticks([0, (-LOWER)/2, -LOWER])\n",
    "\n",
    "# Right: positive (Greys)\n",
    "if len(w_pos):\n",
    "    sm_pos = ScalarMappable(cmap=plt.cm.Greys,\n",
    "                            norm=Normalize(vmin=0.0, vmax=float(UPPER)))\n",
    "    sm_pos.set_array([])\n",
    "    cax_pos = inset_axes(\n",
    "        ax, width=\"32%\", height=\"3%\", loc=\"lower right\",\n",
    "        bbox_to_anchor=(-0.06, -0.12, 1.0, 1.0),  # right aligned\n",
    "        bbox_transform=ax.transAxes, borderpad=0\n",
    "    )\n",
    "    cbar_pos = fig.colorbar(sm_pos, cax=cax_pos, orientation='horizontal')\n",
    "    cbar_pos.set_label('Positive weight', labelpad=2)\n",
    "    cbar_pos.ax.xaxis.set_label_position('bottom')\n",
    "    cbar_pos.ax.xaxis.set_ticks_position('bottom')\n",
    "    cbar_pos.set_ticks([0, UPPER/2, UPPER])\n",
    "\n",
    "out_path = f\"{OUTPUT_DIR}/ANN.svg\"\n",
    "fig.savefig(out_path, dpi=800)\n",
    "plt.show()\n",
    "plt.close(fig)\n",
    "\n",
    "print(f\"Visualization saved to: {out_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc249918",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import jax.tree_util as tree_util\n",
    "\n",
    "# SAVING THE BEST GENOME\n",
    "\n",
    "# The best_genome is a JAX PyTree living on the GPU/TPU.\n",
    "# For safe saving, we first pull it to the CPU and convert it to NumPy arrays.\n",
    "best_genome_numpy = tree_util.tree_map(jax.device_get, best_genome)\n",
    "\n",
    "# Define the filename\n",
    "save_filename = f\"{OUTPUT_DIR}/best_genome.pkl\"\n",
    "\n",
    "# Use pickle to serialize and save the NumPy version of the genome\n",
    "with open(save_filename, \"wb\") as f:\n",
    "    pickle.dump(best_genome_numpy, f)\n",
    "\n",
    "print(f\"Best genome saved successfully to: {save_filename}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jax",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
