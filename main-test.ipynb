{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "476a7ffb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export LD_LIBRARY_PATH=$LD_LIBRARY_PATH:/home/andi/.mujoco/mujoco210/bin\n",
    "# export LD_LIBRARY_PATH=$LD_LIBRARY_PATH:/home/andi/.mujoco/mujoco-3.3.5/bin\n",
    "\n",
    "# export LD_LIBRARY_PATH=$LD_LIBRARY_PATH:/usr/lib/nvidia\n",
    "# export LD_LIBRARY_PATH=$LD_LIBRARY_PATH:/lib/i386-linux-gnu/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31ec82b6",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'output/ant'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 45\u001b[0m\n\u001b[1;32m     43\u001b[0m OUTPUT_DIR \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moutput/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mEXPERIMENT_NAME\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     44\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mexists(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mOUTPUT_DIR\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m---> 45\u001b[0m     \u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmkdir\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mOUTPUT_DIR\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     46\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m HIDDEN_DEPTH \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAt least one hidden layer is required for FullSubstrate\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'output/ant'"
     ]
    }
   ],
   "source": [
    "import jax\n",
    "import jax.numpy as jnp\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorneat.algorithm.neat import NEAT\n",
    "from tensorneat.algorithm.hyperneat import HyperNEAT, FullSubstrate, HyperNEATFeedForward\n",
    "from tensorneat.genome import DefaultGenome\n",
    "from tensorneat.genome.operations import DefaultMutation\n",
    "from tensorneat.genome.gene import DefaultConn\n",
    "from tensorneat.problem import BraxEnv\n",
    "from tensorneat.common import ACT\n",
    "\n",
    "import wandb\n",
    "from custom_pipeline import CustomPipeline\n",
    "from dim_mapping import SubstrateGenerator\n",
    "import os\n",
    "\n",
    "# change log\n",
    "\n",
    "\n",
    "# next change: hidden layers number, hidden layers type, higher mutation rates\n",
    "\n",
    "WANDB_NAME_SUFFIX = \"repeat_times\"\n",
    "\n",
    "env_name = \"ant\"  # @param ['ant', 'halfcheetah', 'hopper', 'humanoid', 'humanoidstandup', 'inverted_pendulum', 'inverted_double_pendulum', 'pusher', 'reacher', 'walker2d']\n",
    "env_backend = \"positional\" # @param ['generalized', 'positional', 'spring']\n",
    "\n",
    "HIDDEN_LAYER_TYPE = \"two_hot\"           # shift / one_hot / two_hot\n",
    "MAX_STEP = 1000\n",
    "GENERATION_LIMIT = 50\n",
    "FITNESS_TARGET = 10000.0\n",
    "EXPERIMENT_NAME = f\"{env_name}\"\n",
    "POP_SIZE = 1000\n",
    "SPECIES_SIZE = 10\n",
    "WEIGHT_TRESHOLD = 0.1\n",
    "HIDDEN_DEPTH = 2\n",
    "REPEAT_TIMES = 5 \n",
    "\n",
    "# specific hyperparams for gymnasium env\n",
    "WAVELENGTHS = ()\n",
    "COSINE_WAVE = False\n",
    "\n",
    "OUTPUT_DIR = f\"output/{EXPERIMENT_NAME}\"\n",
    "if not os.path.exists(f\"output\"):\n",
    "    os.mkdir(\"output\")\n",
    "if not os.path.exists(f\"{OUTPUT_DIR}\"):\n",
    "    os.mkdir(f\"{OUTPUT_DIR}\")\n",
    "assert HIDDEN_DEPTH > 0, \"At least one hidden layer is required for FullSubstrate\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88a29815",
   "metadata": {},
   "outputs": [],
   "source": [
    "env_problem = BraxEnv(\n",
    "    env_name=env_name,\n",
    "    backend=env_backend,\n",
    "    max_step=MAX_STEP,\n",
    "    repeat_times=REPEAT_TIMES,\n",
    "    obs_normalization=False,\n",
    "    sample_episodes=16,\n",
    "    )\n",
    "OBS_SIZE = env_problem.input_shape[0]\n",
    "ACT_SIZE = env_problem.output_shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffca9e31",
   "metadata": {},
   "outputs": [],
   "source": [
    "substrate_gen = SubstrateGenerator(\n",
    "    env_name=env_name,\n",
    "    obs_size=OBS_SIZE,\n",
    "    act_size=ACT_SIZE,\n",
    "    hidden_layer_type=HIDDEN_LAYER_TYPE,\n",
    "    hidden_depth=HIDDEN_DEPTH,\n",
    "    wavelengths=WAVELENGTHS,\n",
    "    cosine_wave=COSINE_WAVE,\n",
    ")\n",
    "\n",
    "input_coors, coord_size = substrate_gen.get_input_coors()\n",
    "hidden_coors = substrate_gen.get_hidden_coors(input_coors, coord_size)\n",
    "output_coors = substrate_gen.get_output_coors(coord_size)\n",
    "\n",
    "print(f\"Final COORD_SIZE: {coord_size}\")\n",
    "print(f\"Number of input neurons: {len(input_coors)}\")\n",
    "print(input_coors)\n",
    "print(f\"Number of hidden neurons: {len(hidden_coors)}\")\n",
    "print(f\"Number of output neurons: {len(output_coors)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37dd80a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Create the substrate\n",
    "active_substrate = FullSubstrate(\n",
    "    input_coors=input_coors,\n",
    "    hidden_coors=hidden_coors,\n",
    "    output_coors=output_coors,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2a9abc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"query_coors shape:\", active_substrate.query_coors.shape)  # (num_queries, query_dim)\n",
    "query_dim = int(active_substrate.query_coors.shape[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9693d0ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "WEIGHT_LOWER_BOUND=-1.0\n",
    "WEIGHT_UPPER_BOUND=1.0\n",
    "\n",
    "conn_gene = DefaultConn(\n",
    "    weight_mutate_power=0.25,\n",
    "    weight_mutate_rate=0.3,\n",
    "    weight_lower_bound=WEIGHT_LOWER_BOUND,\n",
    "    weight_upper_bound=WEIGHT_UPPER_BOUND,\n",
    ")\n",
    "\n",
    "genome=DefaultGenome(\n",
    "    num_inputs=query_dim,\n",
    "    num_outputs=1,\n",
    "    output_transform=ACT.tanh,\n",
    "    max_nodes=256,\n",
    "    max_conns=1024,\n",
    "    init_hidden_layers=[int(query_dim/4)],\n",
    "    mutation=DefaultMutation(\n",
    "        node_add=0.4,\n",
    "        conn_add=0.5, \n",
    "        node_delete=0.15,\n",
    "        conn_delete=0.2,\n",
    "    ),\n",
    "    conn_gene=conn_gene,\n",
    ")\n",
    "\n",
    "neat_algorithm = NEAT(\n",
    "    pop_size=POP_SIZE,\n",
    "    species_size=SPECIES_SIZE,\n",
    "    survival_threshold=0.2,\n",
    "    compatibility_threshold=1.0,\n",
    "    species_fitness_func=jnp.max, # alternative jnp.mean / jnp.max,\n",
    "    spawn_number_change_rate=0.5,\n",
    "    genome_elitism=5,\n",
    "    species_elitism=3,\n",
    "    genome=genome,\n",
    ")\n",
    "\n",
    "evol_algorithm = HyperNEAT(\n",
    "    substrate=active_substrate,\n",
    "    neat=neat_algorithm,\n",
    "    activation=ACT.tanh,\n",
    "    activate_time=25, # How many internal activation steps per simulation step (recurrence)\n",
    "    output_transform=ACT.tanh,\n",
    "    weight_threshold=WEIGHT_TRESHOLD,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0217f420",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Total observation shape:\", env_problem.input_shape)\n",
    "print(\"Total action shape:\", env_problem.output_shape)\n",
    "\n",
    "print(\"Substrate input dimension:\", active_substrate.query_coors.shape[1])\n",
    "print(\"Algorithm input dimension:\", evol_algorithm.num_inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54753d15",
   "metadata": {},
   "outputs": [],
   "source": [
    "wanbd_name = f\"{EXPERIMENT_NAME}_{WANDB_NAME_SUFFIX}\"\n",
    "WANDB_TAGS = [HIDDEN_LAYER_TYPE, env_name]\n",
    "\n",
    "wandb.init(name=wanbd_name, project=\"connection_cost\", tags=WANDB_TAGS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e5221b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = CustomPipeline(\n",
    "    algorithm=evol_algorithm,\n",
    "    problem=env_problem,\n",
    "    seed=42,\n",
    "    generation_limit=GENERATION_LIMIT,\n",
    "    fitness_target=FITNESS_TARGET,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d316ddbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "init_state = pipeline.setup()\n",
    "state = pipeline.auto_run(\n",
    "    state=init_state\n",
    ")\n",
    "\n",
    "print(f\"\\nTraining finished. Best fitness achieved: {pipeline.best_fitness}\")\n",
    "\n",
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7ac61df",
   "metadata": {},
   "outputs": [],
   "source": [
    "state_for_show = state[0] if isinstance(state, tuple) else state\n",
    "\n",
    "# Transform the best genome into network parameters\n",
    "best_genome = pipeline.best_genome\n",
    "\n",
    "# Use the built-in show method to visualize and save video\n",
    "pipeline.show(\n",
    "    state=state_for_show,\n",
    "    best=best_genome,\n",
    "    output_type=\"mp4\",\n",
    "    save_path=f\"{OUTPUT_DIR}/agent.mp4\",\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4339fa64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize cppn\n",
    "cppn_genome = pipeline.algorithm.neat.genome\n",
    "cppn_network = cppn_genome.network_dict(state, *best_genome)\n",
    "cppn_genome.visualize(cppn_network, save_path=f\"{OUTPUT_DIR}/cppn_network.svg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff16c13d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "from matplotlib.colors import Normalize\n",
    "from matplotlib.cm import ScalarMappable\n",
    "\n",
    "print(\"Manually reconstructing the phenotype. A visual layout will be generated.\")\n",
    "\n",
    "# 1) Weights from CPPN (your existing logic)\n",
    "neat_algorithm = pipeline.algorithm.neat\n",
    "cppn_params = neat_algorithm.transform(state, best_genome)\n",
    "query_coors = active_substrate.query_coors\n",
    "cppn_forward_func = neat_algorithm.forward\n",
    "\n",
    "all_substrate_weights = jax.vmap(\n",
    "    cppn_forward_func, in_axes=(None, None, 0)\n",
    ")(state, cppn_params, query_coors)\n",
    "\n",
    "all_substrate_connections = np.array(active_substrate.conns)\n",
    "all_substrate_weights_np = np.array(all_substrate_weights).squeeze()\n",
    "\n",
    "# 2) Select edges: no percentile pruning; keep internal threshold (toggleable)\n",
    "internal_weight_threshold = pipeline.algorithm.weight_threshold\n",
    "active_mask = np.abs(all_substrate_weights_np) > internal_weight_threshold\n",
    "active_conns = all_substrate_connections[active_mask]\n",
    "active_weights = all_substrate_weights_np[active_mask]\n",
    "\n",
    "# If you want literally every potential connection regardless of threshold:\n",
    "# active_conns = all_substrate_connections\n",
    "# active_weights = all_substrate_weights_np\n",
    "\n",
    "print(f\"Substrate has {len(all_substrate_connections)} potential connections.\")\n",
    "\n",
    "# Build graph, assign layers, generate layout\n",
    "G_to_draw = nx.DiGraph()\n",
    "all_node_keys = [int(n[0]) for n in active_substrate.nodes]\n",
    "\n",
    "\n",
    "# Which coordinate dimension encodes \"layer\"? In your code it's the last one.\n",
    "LAYER_AXIS = -1  # last coordinate\n",
    "\n",
    "def compute_hidden_layer_groups(hidden_coors, layer_axis=LAYER_AXIS):\n",
    "    \"\"\"\n",
    "    Returns:\n",
    "    order_vals: sorted unique layer values (e.g., 3, 6, 9, ...)\n",
    "    idx_groups: list of lists; each inner list has indices of hidden nodes that belong to that layer\n",
    "    widths:     number of hidden nodes per layer (len of each group)\n",
    "    \"\"\"\n",
    "    hc = np.asarray(hidden_coors)\n",
    "    if hc.ndim != 2:\n",
    "        raise ValueError(f\"hidden_coors must be 2D (num_hidden, coord_dims); got shape {hc.shape}\")\n",
    "\n",
    "    layer_vals = hc[:, layer_axis]\n",
    "    order_vals = np.unique(layer_vals)\n",
    "    idx_groups = [np.where(layer_vals == v)[0].tolist() for v in order_vals]\n",
    "    widths = [len(g) for g in idx_groups]\n",
    "    return order_vals.tolist(), idx_groups, widths\n",
    "\n",
    "# Example usage:\n",
    "order_vals, hidden_idx_groups, hidden_widths = compute_hidden_layer_groups(hidden_coors, layer_axis=LAYER_AXIS)\n",
    "# All node keys in substrate order (N,1) -> flatten to ints\n",
    "all_node_keys = [int(n[0]) for n in active_substrate.nodes]\n",
    "\n",
    "num_inputs  = len(input_coors)\n",
    "num_outputs = len(output_coors)\n",
    "num_hiddens = len(hidden_coors)\n",
    "\n",
    "# Correct slicing for FullSubstrate:\n",
    "input_keys  = all_node_keys[:num_inputs]\n",
    "output_keys = all_node_keys[num_inputs : num_inputs + num_outputs]\n",
    "hidden_keys = all_node_keys[num_inputs + num_outputs : num_inputs + num_outputs + num_hiddens]\n",
    "\n",
    "# Add nodes to the graph with subsets (partitions) for visualization\n",
    "G_to_draw = nx.DiGraph()\n",
    "\n",
    "# Inputs at layer 0\n",
    "for k in input_keys:\n",
    "    G_to_draw.add_node(k, subset=0)\n",
    "\n",
    "# Hidden layers (1..HIDDEN_DEPTH) — we map the *contiguous* hidden range to layers\n",
    "start_hidden = num_inputs + num_outputs\n",
    "\n",
    "# If each hidden layer has the same width (classic case):\n",
    "# hidden_width_full = len(input_coors)  # or len(hidden_coors)//HIDDEN_DEPTH\n",
    "# But we will use the robust per-layer widths we computed above:\n",
    "cum = 0\n",
    "for j, w in enumerate(hidden_widths):\n",
    "    layer_id = j + 1\n",
    "    start = start_hidden + cum\n",
    "    end   = start + w\n",
    "    for i in range(start, min(end, len(all_node_keys))):\n",
    "        G_to_draw.add_node(all_node_keys[i], subset=layer_id)\n",
    "    cum += w\n",
    "\n",
    "# Outputs at the final layer (after all hidden layers)\n",
    "output_layer_id = HIDDEN_DEPTH + 1\n",
    "for k in output_keys:\n",
    "    G_to_draw.add_node(k, subset=output_layer_id)\n",
    "\n",
    "\n",
    "# Layout from the detailed layer assignment\n",
    "pos = nx.multipartite_layout(G_to_draw, subset_key='subset')\n",
    "\n",
    "# 4) Fixed-bounds grayscale mapping & robust edge extraction\n",
    "\n",
    "# Helper: coerce bounds to floats (in case 0,0 was typed instead of 0.0)\n",
    "def _to_float_bound(x, name):\n",
    "    if isinstance(x, (tuple, list, np.ndarray)):\n",
    "        if len(x) == 0:\n",
    "            raise ValueError(f\"{name} is empty; set a valid float (e.g., 0.0).\")\n",
    "        x = x[0]\n",
    "    try:\n",
    "        return float(x)\n",
    "    except Exception as e:\n",
    "        raise ValueError(\n",
    "            f\"Could not convert {name}={x!r} to float. \"\n",
    "            f\"Use a scalar like 0.0 or 1.0. Original error: {e}\"\n",
    "        )\n",
    "\n",
    "LOWER = _to_float_bound(WEIGHT_LOWER_BOUND, \"WEIGHT_LOWER_BOUND\")\n",
    "UPPER = _to_float_bound(WEIGHT_UPPER_BOUND, \"WEIGHT_UPPER_BOUND\")\n",
    "\n",
    "# Your active_conns rows look like [src, dst, extra]; take first two columns\n",
    "ac = np.asarray(active_conns)\n",
    "if ac.ndim != 2 or ac.shape[1] < 2:\n",
    "    raise ValueError(f\"Expected active_conns to have at least 2 columns; got shape {ac.shape}\")\n",
    "\n",
    "all_edges = [(int(row[0]), int(row[1])) for row in ac]\n",
    "all_weights = np.asarray(active_weights)\n",
    "\n",
    "# NEW: Filter out self-loops\n",
    "# Create lists to hold the edges and weights that are NOT self-loops\n",
    "edges_to_add = []\n",
    "active_weights_filtered = []\n",
    "for edge, weight in zip(all_edges, all_weights):\n",
    "    if edge[0] != edge[1]:  # This condition checks if the edge is NOT a self-loop\n",
    "        edges_to_add.append(edge)\n",
    "        active_weights_filtered.append(weight)\n",
    "\n",
    "# Convert back to a NumPy array for consistency\n",
    "active_weights = np.array(active_weights_filtered)\n",
    "\n",
    "print(f\"Visualizing {len(active_weights)} connections. Excluded loops. Weight threshold: {internal_weight_threshold}\")\n",
    "\n",
    "# Add edges to graph\n",
    "G_to_draw.add_edges_from(edges_to_add)\n",
    "\n",
    "# Magnitudes for color mapping (must align 1:1 with edges_to_add)\n",
    "abs_w = np.abs(active_weights)\n",
    "if len(abs_w) != len(edges_to_add):\n",
    "    raise ValueError(\n",
    "        f\"Edge/weight mismatch: {len(edges_to_add)} edges vs {len(abs_w)} weights. \"\n",
    "        \"Ensure any filtering is applied identically to connections and weights.\"\n",
    "    )\n",
    "\n",
    "# Edge-width scaling (optional) using fixed bounds in [0,1]\n",
    "if abs_w.size > 0:\n",
    "    norm_for_widths = np.clip((abs_w - LOWER) / (UPPER - LOWER), 0.0, 1.0)\n",
    "else:\n",
    "    norm_for_widths = np.array([], dtype=float)\n",
    "\n",
    "# Node colors: inputs=blue, outputs=red, hidden=green\n",
    "node_colors = []\n",
    "for node_key in G_to_draw.nodes():\n",
    "    if node_key in input_keys:\n",
    "        color = 'blue'\n",
    "    elif node_key in output_keys:\n",
    "        color = 'red'\n",
    "    else:\n",
    "        color = 'green'\n",
    "    node_colors.append(color)\n",
    "\n",
    "# 5) Draw with separate colormaps for positive (Greys) and negative (Reds)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(12, 12))\n",
    "\n",
    "weights = np.asarray(active_weights)\n",
    "idx_all = np.arange(len(edges_to_add))\n",
    "\n",
    "pos_idx = idx_all[weights > 0]\n",
    "neg_idx = idx_all[weights < 0]\n",
    "zero_idx = idx_all[weights == 0]  # optional\n",
    "\n",
    "edges_pos = [edges_to_add[i] for i in pos_idx]\n",
    "edges_neg = [edges_to_add[i] for i in neg_idx]\n",
    "w_pos = weights[pos_idx]                # > 0\n",
    "w_neg_mag = -weights[neg_idx]           # positive magnitudes for negative edges\n",
    "\n",
    "# Edge widths scaled per side using fixed bounds\n",
    "eps = np.finfo(float).eps  # protect against division by zero\n",
    "\n",
    "widths_pos = 0.5 + 1.5 * np.clip(w_pos / max(UPPER, eps), 0.0, 1.0) if len(w_pos) else []\n",
    "widths_neg = 0.5 + 1.5 * np.clip(w_neg_mag / max(-LOWER, eps), 0.0, 1.0) if len(w_neg_mag) else []\n",
    "\n",
    "# Draw nodes once\n",
    "nx.draw_networkx_nodes(\n",
    "    G_to_draw,\n",
    "    pos=pos,\n",
    "    node_color=node_colors,\n",
    "    node_size=20,\n",
    "    ax=ax\n",
    ")\n",
    "\n",
    "# Draw POSITIVE edges: Greys (white → black), mapped over [0, UPPER]\n",
    "if len(edges_pos):\n",
    "    nx.draw_networkx_edges(\n",
    "        G_to_draw,\n",
    "        pos=pos,\n",
    "        edgelist=edges_pos,\n",
    "        edge_color=w_pos,             # raw positive weights\n",
    "        edge_cmap=plt.cm.Greys,\n",
    "        edge_vmin=0.0,\n",
    "        edge_vmax=float(UPPER),\n",
    "        width=widths_pos,\n",
    "        arrows=True,\n",
    "        arrowstyle='-|>',\n",
    "        arrowsize=4,\n",
    "        ax=ax\n",
    "    )\n",
    "\n",
    "# Draw NEGATIVE edges: Reds (white → red), mapped over [0, |LOWER|] using magnitudes\n",
    "if len(edges_neg):\n",
    "    nx.draw_networkx_edges(\n",
    "        G_to_draw,\n",
    "        pos=pos,\n",
    "        edgelist=edges_neg,\n",
    "        edge_color=w_neg_mag,         # magnitudes of negative weights\n",
    "        edge_cmap=plt.cm.Reds,\n",
    "        edge_vmin=0.0,\n",
    "        edge_vmax=float(-LOWER),\n",
    "        width=widths_neg,\n",
    "        arrows=True,\n",
    "        arrowstyle='-|>',\n",
    "        arrowsize=4,\n",
    "        ax=ax\n",
    "    )\n",
    "\n",
    "# Optional: draw exact-zero edges very faint (skip if you keep an internal threshold > 0)\n",
    "# if len(zero_idx):\n",
    "#     edges_zero = [edges_to_add[i] for i in zero_idx]\n",
    "#     nx.draw_networkx_edges(\n",
    "#         G_to_draw, pos=pos, edgelist=edges_zero, edge_color=\"#eeeeee\",\n",
    "#         width=0.5, arrows=True, arrowstyle='-|>', arrowsize=3, ax=ax\n",
    "#     )\n",
    "\n",
    "# Colorbars\n",
    "from matplotlib.colors import Normalize\n",
    "from matplotlib.cm import ScalarMappable\n",
    "from mpl_toolkits.axes_grid1.inset_locator import inset_axes\n",
    "\n",
    "ax.set_title(f\"Substrate Network — Positives Greys, Negatives Reds (Bounds [{LOWER}, {UPPER}])\")\n",
    "fig.tight_layout()\n",
    "fig.subplots_adjust(bottom=0.18) # Manually make space at the bottom for colorbars\n",
    "\n",
    "# Left: negative (Reds)\n",
    "if len(w_neg_mag):\n",
    "    sm_neg = ScalarMappable(cmap=plt.cm.Reds,\n",
    "                            norm=Normalize(vmin=0.0, vmax=float(-LOWER)))\n",
    "    sm_neg.set_array([])\n",
    "    cax_neg = inset_axes(\n",
    "        ax, width=\"32%\", height=\"3%\", loc=\"lower left\",\n",
    "        bbox_to_anchor=(0.06, -0.12, 1.0, 1.0),  # left aligned\n",
    "        bbox_transform=ax.transAxes, borderpad=0\n",
    "    )\n",
    "    cbar_neg = fig.colorbar(sm_neg, cax=cax_neg, orientation='horizontal')\n",
    "    cbar_neg.set_label('Negative |weight|', labelpad=2)\n",
    "    cbar_neg.ax.xaxis.set_label_position('bottom')\n",
    "    cbar_neg.ax.xaxis.set_ticks_position('bottom')\n",
    "    cbar_neg.set_ticks([0, (-LOWER)/2, -LOWER])\n",
    "\n",
    "# Right: positive (Greys)\n",
    "if len(w_pos):\n",
    "    sm_pos = ScalarMappable(cmap=plt.cm.Greys,\n",
    "                            norm=Normalize(vmin=0.0, vmax=float(UPPER)))\n",
    "    sm_pos.set_array([])\n",
    "    cax_pos = inset_axes(\n",
    "        ax, width=\"32%\", height=\"3%\", loc=\"lower right\",\n",
    "        bbox_to_anchor=(-0.06, -0.12, 1.0, 1.0),  # right aligned\n",
    "        bbox_transform=ax.transAxes, borderpad=0\n",
    "    )\n",
    "    cbar_pos = fig.colorbar(sm_pos, cax=cax_pos, orientation='horizontal')\n",
    "    cbar_pos.set_label('Positive weight', labelpad=2)\n",
    "    cbar_pos.ax.xaxis.set_label_position('bottom')\n",
    "    cbar_pos.ax.xaxis.set_ticks_position('bottom')\n",
    "    cbar_pos.set_ticks([0, UPPER/2, UPPER])\n",
    "\n",
    "out_path = f\"{OUTPUT_DIR}/ANN.svg\"\n",
    "fig.savefig(out_path, dpi=800)\n",
    "plt.show()\n",
    "plt.close(fig)\n",
    "\n",
    "print(f\"Visualization saved to: {out_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc249918",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import jax.tree_util as tree_util\n",
    "\n",
    "# SAVING THE BEST GENOME\n",
    "\n",
    "# The best_genome is a JAX PyTree living on the GPU/TPU.\n",
    "# For safe saving, we first pull it to the CPU and convert it to NumPy arrays.\n",
    "best_genome_numpy = tree_util.tree_map(jax.device_get, best_genome)\n",
    "\n",
    "# Define the filename\n",
    "save_filename = f\"{OUTPUT_DIR}/best_genome.pkl\"\n",
    "\n",
    "# Use pickle to serialize and save the NumPy version of the genome\n",
    "with open(save_filename, \"wb\") as f:\n",
    "    pickle.dump(best_genome_numpy, f)\n",
    "\n",
    "print(f\"Best genome saved successfully to: {save_filename}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0bb8129",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LOADING AND RESUMING TRAINING\n",
    "\n",
    "resume = False\n",
    "\n",
    "if resume:\n",
    "    # 1. Define the filename of the genome you want to load\n",
    "    load_filename = f\"{OUTPUT_DIR}/best_genome.pkl\"\n",
    "\n",
    "    # 2. Load the genome using pickle\n",
    "    try:\n",
    "        with open(load_filename, \"rb\") as f:\n",
    "            loaded_genome = pickle.load(f)\n",
    "        print(f\"Successfully loaded genome from: {load_filename}\")\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: Genome file not found at {load_filename}. Cannot resume training.\")\n",
    "        loaded_genome = None\n",
    "\n",
    "    if loaded_genome:\n",
    "        # 3. Create a new pipeline instance (ensure all parameters are the same as the saving run!)\n",
    "        #    This is important, as the loaded genome's structure must match the pipeline's genome definition.\n",
    "        resume_pipeline = CustomPipeline(\n",
    "            algorithm=evol_algorithm,\n",
    "            problem=env_problem,\n",
    "            seed=43, # Use a different seed for the new run\n",
    "            generation_limit=GENERATION_LIMIT,\n",
    "            fitness_target=FITNESS_TARGET,\n",
    "        )\n",
    "\n",
    "        # 4. Create the initial, random state and population\n",
    "        print(\"Setting up initial random population...\")\n",
    "        state = resume_pipeline.setup()\n",
    "\n",
    "        # 5. Manually insert the loaded genome into the population\n",
    "        #    A population is a PyTree (tuple) of (nodes_array, conns_array).\n",
    "        #    We will replace the individual at index 0.\n",
    "        \n",
    "        current_pop = state.population\n",
    "        \n",
    "        # Use JAX's recommended immutable update syntax\n",
    "        new_nodes = current_pop[0].at[0].set(loaded_genome[0])\n",
    "        new_conns = current_pop[1].at[0].set(loaded_genome[1])\n",
    "        \n",
    "        new_population = (new_nodes, new_conns)\n",
    "        \n",
    "        # Update the state with the new population that contains our champion\n",
    "        state = state.replace(population=new_population)\n",
    "        \n",
    "        print(\"Best genome from previous run has been inserted into the new population.\")\n",
    "\n",
    "        # 6. Start the new training run with the modified state\n",
    "        print(\"Resuming training...\")\n",
    "        state = resume_pipeline.train_custom(\n",
    "            state=state, # Pass the modified state in\n",
    "            log=True,\n",
    "            on_generation=lambda gen, state, pop, fitnesses: print(f\"Gen {gen+1} finished evolution.\")\n",
    "        )\n",
    "        \n",
    "        # SAVING THE BEST GENOME\n",
    "\n",
    "        best_genome = resume_pipeline.best_genome\n",
    "\n",
    "        # The best_genome is a JAX PyTree living on the GPU/TPU.\n",
    "        # For safe saving, we first pull it to the CPU and convert it to NumPy arrays.\n",
    "        best_genome_numpy = tree_util.tree_map(jax.device_get, best_genome)\n",
    "\n",
    "        # Define the filename\n",
    "        save_filename = f\"{OUTPUT_DIR}/best_genome.pkl\"\n",
    "\n",
    "        # Use pickle to serialize and save the NumPy version of the genome\n",
    "        with open(save_filename, \"wb\") as f:\n",
    "            pickle.dump(best_genome_numpy, f)\n",
    "\n",
    "        print(f\"Best genome saved successfully to: {save_filename}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jax",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
