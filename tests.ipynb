{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "31ec82b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import jax\n",
    "import numpy as np\n",
    "import wandb\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import defaultdict\n",
    "\n",
    "from config import config\n",
    "from tensorneat.algorithm.hyperneat import FullSubstrate, MLPSubstrate, DefaultSubstrate\n",
    "from substrate_generation.pca_coor_generator import PCAanalyzer \n",
    "from substrate_generation.pca_inv_coor_generator import InvPCAanalyzer \n",
    "from substrate_generation.sdl_coor_generator import SparseDictionaryAnalyzer\n",
    "from substrate_generation.fa_coor_generator import FactorAnalyzer\n",
    "from substrate_generation.manual_coor_generator import ManualIOMapper\n",
    "from substrate_generation.random_coor_generator import RandomCoordinateGenerator\n",
    "from substrate_generation.data_sampling import collect_random_policy_data, collect_trained_agent_policy_data\n",
    "from evol_pipeline.brax_env import CustomBraxEnv\n",
    "from evol_pipeline.custom_pipeline import CustomPipeline\n",
    "from evol_pipeline.custom_substrate import AutoLayeredCoordMLPSubstrate\n",
    "from substrate_generation.hidden_layers import HiddenLayerGenerator\n",
    "from utils.visualization import visualize_cppn, visualize_nn, display_plots_side_by_side\n",
    "from utils.utils import save_coordinates_to_csv, setup_folder_structure\n",
    "from evol_pipeline.evol_algorithm import create_evol_algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "79b4677d",
   "metadata": {},
   "outputs": [],
   "source": [
    "OUTPUT_DIR = config[\"experiment\"][\"output_dir\"]\n",
    "setup_folder_structure(OUTPUT_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "88a29815",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/andi/anaconda3/envs/jax/lib/python3.10/site-packages/brax/io/mjcf.py:480: UserWarning: Brax System, piplines and environments are not actively being maintained. Please see MJX for a well maintained JAX-based physics engine: https://github.com/google-deepmind/mujoco/tree/main/mjx. For a host of environments that use MJX, see: https://github.com/google-deepmind/mujoco_playground.\n",
      "  warnings.warn(\n",
      "2025-10-15 08:25:35.639236: W external/xla/xla/service/gpu/autotuning/dot_search_space.cc:200] All configs were filtered out because none of them sufficiently match the hints. Maybe the hints set does not contain a good representative set of valid configs?Working around this by using the full hints set instead.\n",
      "2025-10-15 08:25:46.977187: W external/xla/xla/service/gpu/autotuning/dot_search_space.cc:200] All configs were filtered out because none of them sufficiently match the hints. Maybe the hints set does not contain a good representative set of valid configs?Working around this by using the full hints set instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env_problem.input_shape:  (27,)\n",
      "env_problem.input_shape:  (8,)\n"
     ]
    }
   ],
   "source": [
    "env_name = config[\"experiment\"][\"env_name\"]\n",
    "env_problem = CustomBraxEnv(\n",
    "    env_name=env_name,\n",
    "    backend=config[\"environment\"][\"backend\"],\n",
    "    brax_args=config[\"environment\"][\"brax_args\"],\n",
    "    max_step=config[\"environment\"][\"max_step\"],\n",
    "    repeat_times=config[\"environment\"][\"repeat_times\"],\n",
    "    obs_normalization=False,\n",
    "    sample_episodes=16,\n",
    ")\n",
    "obs_size = env_problem.input_shape[0]\n",
    "act_size = env_problem.output_shape[0]\n",
    "feature_dims = config[\"data_analysis\"][\"feature_dims\"]\n",
    "\n",
    "print(\"env_problem.input_shape: \", env_problem.input_shape)\n",
    "print(\"env_problem.input_shape: \", env_problem.output_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f5af6fe3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting data collection for 5000 steps using a random policy...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-15 08:25:53.234099: W external/xla/xla/service/gpu/autotuning/dot_search_space.cc:200] All configs were filtered out because none of them sufficiently match the hints. Maybe the hints set does not contain a good representative set of valid configs?Working around this by using the full hints set instead.\n",
      "2025-10-15 08:25:53.234113: W external/xla/xla/service/gpu/autotuning/dot_search_space.cc:200] All configs were filtered out because none of them sufficiently match the hints. Maybe the hints set does not contain a good representative set of valid configs?Working around this by using the full hints set instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Causal data collection finished.\n"
     ]
    }
   ],
   "source": [
    "key = jax.random.PRNGKey(config[\"experiment\"][\"seed\"]) # Use seed from config\n",
    "key, random_key = jax.random.split(key)\n",
    "num_random_sampling_steps = 5000\n",
    "random_data = collect_random_policy_data(env_problem, random_key, num_random_sampling_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e4334341",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analyzing random sampling data\n",
      "Running PCA to find feature dimensions covering 65.0% of variance (with a hard limit of 7 dimensions)...\n",
      "PCA found 15 dimensions needed for 65.0% variance.\n",
      "Applying max limit. Final number of feature dimensions: 7\n",
      "Normalizing coordinates...\n",
      "Added layering dimension. Final coordinate size: 8\n",
      "PCA variance plot saved to: output/ant/data_analysis/pca_variance_65_random.png\n",
      "Principal component heatmap saved to: output/ant/data_analysis/pca_heatmap_65_random.png\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "variance = config[\"data_analysis\"][\"variance_threshold\"]\n",
    "percentage = int(variance*100)\n",
    "\n",
    "print(f\"Analyzing random sampling data\")\n",
    "analyzer_pca = PCAanalyzer(\n",
    "    data=random_data, \n",
    "    obs_size=obs_size, \n",
    "    act_size=act_size,\n",
    "    variance_threshold=variance, \n",
    "    feature_dims=feature_dims,\n",
    "    hidden_depth=config[\"substrate\"][\"hidden_depth\"],\n",
    "    width_factor=config[\"substrate\"][\"width_factor\"],\n",
    "    normalize_coors=config[\"data_analysis\"][\"normalize_coors\"],\n",
    "    depth_factor=config[\"substrate\"][\"depth_factor\"],\n",
    ")\n",
    "input_coors, output_coors = analyzer_pca.generate_io_coordinates()\n",
    "analyzer_pca.plot_variance(save_path=f\"{OUTPUT_DIR}/data_analysis/pca_variance_{percentage}_random.png\")\n",
    "analyzer_pca.plot_principal_components(save_path=f\"{OUTPUT_DIR}/data_analysis/pca_heatmap_{percentage}_random.png\")\n",
    "print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "320b6ce0",
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_layer_gen = HiddenLayerGenerator(\n",
    "    env_name=env_name,\n",
    "    obs_size=obs_size,\n",
    "    act_size=act_size,\n",
    "    hidden_layer_type=config[\"substrate\"][\"hidden_layer_type\"],\n",
    "    hidden_depth=config[\"substrate\"][\"hidden_depth\"],\n",
    "    depth_factor=config[\"substrate\"][\"depth_factor\"],\n",
    "    width_factor=config[\"substrate\"][\"width_factor\"],\n",
    ")\n",
    "\n",
    "substrates = defaultdict(lambda: defaultdict(dict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8f581e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_coors = hidden_layer_gen.get_hidden_coors(input_coors=input_coors)\n",
    "\n",
    "active_substrate = AutoLayeredCoordMLPSubstrate(\n",
    "    input_coors=input_coors,\n",
    "    hidden_coors=hidden_coors,\n",
    "    output_coors=output_coors\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e118c7d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intial CPPN Layers: [2]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mwirkelzirkel\u001b[0m (\u001b[33mwirkelzirkel-iu\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.21.1"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/andi/Dokumente/Bachelorarbeit/dim_tuning/wandb/run-20251015_082608-em5dxb04</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/wirkelzirkel-iu/substrate_dims/runs/em5dxb04' target=\"_blank\">ant_random_pca65_test_8d</a></strong> to <a href='https://wandb.ai/wirkelzirkel-iu/substrate_dims' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/wirkelzirkel-iu/substrate_dims' target=\"_blank\">https://wandb.ai/wirkelzirkel-iu/substrate_dims</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/wirkelzirkel-iu/substrate_dims/runs/em5dxb04' target=\"_blank\">https://wandb.ai/wirkelzirkel-iu/substrate_dims/runs/em5dxb04</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "save to output/ant\n",
      "initializing\n",
      "initializing finished\n",
      "start compile\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-15 08:26:25.958648: W external/xla/xla/hlo/transforms/simplifiers/hlo_rematerialization.cc:3023] Can't reduce memory use below 10.98GiB (11787325176 bytes) by rematerialization; only reduced to 89.07GiB (95643718076 bytes), down from 89.53GiB (96135488976 bytes) originally\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "compile finished, cost time: 34.523917s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-15 08:26:56.891689: W external/xla/xla/tsl/framework/bfc_allocator.cc:501] Allocator (GPU_0_bfc) ran out of memory trying to allocate 59.81GiB (rounded to 64225255424)requested by op \n",
      "If the cause is memory fragmentation maybe the environment variable 'TF_GPU_ALLOCATOR=cuda_malloc_async' will improve the situation. \n",
      "Current allocation summary follows.\n",
      "Current allocation summary follows.\n",
      "2025-10-15 08:26:56.891822: W external/xla/xla/tsl/framework/bfc_allocator.cc:512] *___________________________________________________________________________________________________\n",
      "E1015 08:26:56.891841  760590 pjrt_stream_executor_client.cc:2916] Execution of replica 0 failed: RESOURCE_EXHAUSTED: Out of memory while trying to allocate 64225255216 bytes. [tf-allocator-allocation-error='']\n"
     ]
    },
    {
     "ename": "XlaRuntimeError",
     "evalue": "RESOURCE_EXHAUSTED: Out of memory while trying to allocate 64225255216 bytes.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mXlaRuntimeError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 49\u001b[0m\n\u001b[1;32m     38\u001b[0m pipeline \u001b[38;5;241m=\u001b[39m CustomPipeline(\n\u001b[1;32m     39\u001b[0m     algorithm\u001b[38;5;241m=\u001b[39mevol_algorithm,\n\u001b[1;32m     40\u001b[0m     problem\u001b[38;5;241m=\u001b[39menv_problem,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     45\u001b[0m     save_dir\u001b[38;5;241m=\u001b[39mconfig[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mexperiment\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moutput_dir\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[1;32m     46\u001b[0m )\n\u001b[1;32m     48\u001b[0m init_state \u001b[38;5;241m=\u001b[39m pipeline\u001b[38;5;241m.\u001b[39msetup()\n\u001b[0;32m---> 49\u001b[0m state \u001b[38;5;241m=\u001b[39m \u001b[43mpipeline\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mauto_run\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minit_state\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     51\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mTraining finished. Best fitness achieved: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpipeline\u001b[38;5;241m.\u001b[39mbest_fitness\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     53\u001b[0m wandb\u001b[38;5;241m.\u001b[39mfinish()\n",
      "File \u001b[0;32m~/Dokumente/Bachelorarbeit/dim_tuning/evol_pipeline/custom_pipeline.py:161\u001b[0m, in \u001b[0;36mCustomPipeline.auto_run\u001b[0;34m(self, state)\u001b[0m\n\u001b[1;32m    157\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgeneration_limit):\n\u001b[1;32m    159\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgeneration_timestamp \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[0;32m--> 161\u001b[0m     state, previous_pop, fitnesses \u001b[38;5;241m=\u001b[39m \u001b[43mcompiled_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstate\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    163\u001b[0m     fitnesses \u001b[38;5;241m=\u001b[39m jax\u001b[38;5;241m.\u001b[39mdevice_get(fitnesses)\n\u001b[1;32m    165\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39manalysis(state, previous_pop, fitnesses)\n",
      "File \u001b[0;32m~/anaconda3/envs/jax/lib/python3.10/site-packages/jax/_src/stages.py:556\u001b[0m, in \u001b[0;36mCompiled.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    554\u001b[0m       \u001b[38;5;28;01mreturn\u001b[39;00m outs\n\u001b[1;32m    555\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call \u001b[38;5;241m=\u001b[39m cpp_call_fallback\n\u001b[0;32m--> 556\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/jax/lib/python3.10/site-packages/jax/_src/interpreters/pxla.py:3143\u001b[0m, in \u001b[0;36mMeshExecutable.create_cpp_call.<locals>.aot_cache_miss\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   3141\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21maot_cache_miss\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m   3142\u001b[0m   params \u001b[38;5;241m=\u001b[39m stages\u001b[38;5;241m.\u001b[39mCompiledCallParams(\u001b[38;5;28mself\u001b[39m, no_kwargs, in_tree, out_tree)\n\u001b[0;32m-> 3143\u001b[0m   outs, out_flat, args_flat \u001b[38;5;241m=\u001b[39m \u001b[43mstages\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mCompiled\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3144\u001b[0m   out_flat, out_tree_dispatch \u001b[38;5;241m=\u001b[39m reflatten_outputs_for_dispatch(\n\u001b[1;32m   3145\u001b[0m       out_tree, out_flat)\n\u001b[1;32m   3146\u001b[0m   use_fastpath \u001b[38;5;241m=\u001b[39m (\u001b[38;5;28mall\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, xc\u001b[38;5;241m.\u001b[39mArrayImpl) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m out_flat))\n",
      "File \u001b[0;32m~/anaconda3/envs/jax/lib/python3.10/site-packages/jax/_src/stages.py:525\u001b[0m, in \u001b[0;36mCompiled.call\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    523\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(msg))\n\u001b[1;32m    524\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 525\u001b[0m   out_flat \u001b[38;5;241m=\u001b[39m \u001b[43mparams\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecutable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs_flat\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    526\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    527\u001b[0m   \u001b[38;5;66;03m# We can't transform ahead-of-time compiled calls, since we've\u001b[39;00m\n\u001b[1;32m    528\u001b[0m   \u001b[38;5;66;03m# lowered and compiled for a fixed function signature, and JAX\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    533\u001b[0m   \u001b[38;5;66;03m# might mean that arguments have JAX-invalid types, which in\u001b[39;00m\n\u001b[1;32m    534\u001b[0m   \u001b[38;5;66;03m# turn might mean some are Tracers.\u001b[39;00m\n\u001b[1;32m    535\u001b[0m   \u001b[38;5;28;01mfor\u001b[39;00m arg \u001b[38;5;129;01min\u001b[39;00m args_flat:\n",
      "File \u001b[0;32m~/anaconda3/envs/jax/lib/python3.10/site-packages/jax/_src/interpreters/pxla.py:3133\u001b[0m, in \u001b[0;36mMeshExecutable.call\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   3129\u001b[0m check_arg_avals_for_call(ref_avals, all_arg_avals, debug_info)\n\u001b[1;32m   3130\u001b[0m check_array_xla_sharding_layout_match(\n\u001b[1;32m   3131\u001b[0m     args_after_dce, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_in_shardings, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_xla_in_layouts, debug_info,\n\u001b[1;32m   3132\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_kept_var_idx)\n\u001b[0;32m-> 3133\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43munsafe_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/jax/lib/python3.10/site-packages/jax/_src/profiler.py:354\u001b[0m, in \u001b[0;36mannotate_function.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    351\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(func)\n\u001b[1;32m    352\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mwrapper\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    353\u001b[0m   \u001b[38;5;28;01mwith\u001b[39;00m TraceAnnotation(name, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mdecorator_kwargs):\n\u001b[0;32m--> 354\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/jax/lib/python3.10/site-packages/jax/_src/interpreters/pxla.py:1306\u001b[0m, in \u001b[0;36mExecuteReplicated.__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1304\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_handle_token_bufs(result_token_bufs, sharded_runtime_token)\n\u001b[1;32m   1305\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1306\u001b[0m   results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mxla_executable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute_sharded\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_bufs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1308\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m dispatch\u001b[38;5;241m.\u001b[39mneeds_check_special():\n\u001b[1;32m   1309\u001b[0m   out_arrays \u001b[38;5;241m=\u001b[39m results\u001b[38;5;241m.\u001b[39mdisassemble_into_single_device_arrays()\n",
      "\u001b[0;31mXlaRuntimeError\u001b[0m: RESOURCE_EXHAUSTED: Out of memory while trying to allocate 64225255216 bytes."
     ]
    }
   ],
   "source": [
    "\n",
    "evol_algorithm = create_evol_algorithm(substrate=active_substrate)\n",
    "\n",
    "initial_cppn_layers = config[\"algorithm\"][\"genome\"][\"cppn_init_hidden_layers\"](active_substrate.query_coors.shape[1])\n",
    "print(\"Intial CPPN Layers:\", initial_cppn_layers)\n",
    "\n",
    "substrate_dimensions = int(active_substrate.query_coors.shape[1]/2)\n",
    "\n",
    "wanbd_name = f\"{env_name}_random_pca{percentage}_test_{substrate_dimensions}d\"\n",
    "wandb_tags = [config[\"substrate\"][\"hidden_layer_type\"], env_name, \"pca\", \"random\", \"test\", f\"{config['substrate']['hidden_depth']}_hl\", f\"{config['algorithm']['neat']['pop_size']}pop\", f\"{config['environment']['backend']}\"]\n",
    "\n",
    "wandb.init(\n",
    "    name=wanbd_name,\n",
    "    project=\"substrate_dims\",\n",
    "    tags=wandb_tags,\n",
    "    config=config  \n",
    ")\n",
    "\n",
    "wandb.config.update(\n",
    "    {\n",
    "        \"substrate\": {\n",
    "            \"obs_size\": obs_size,\n",
    "            \"act_size\": act_size,\n",
    "            \"num_queries\": active_substrate.query_coors.shape[0],\n",
    "            \"query_dim\": active_substrate.query_coors.shape[1],\n",
    "            },\n",
    "        \"algorithm\": {\n",
    "            \"neat\": {\n",
    "                \"num_inputs\": evol_algorithm.num_inputs,\n",
    "                },\n",
    "            \"genome\": {\n",
    "                \"cppn_init_hidden_layers\": initial_cppn_layers,\n",
    "                },\n",
    "            },\n",
    "    },\n",
    ")\n",
    "\n",
    "\n",
    "pipeline = CustomPipeline(\n",
    "    algorithm=evol_algorithm,\n",
    "    problem=env_problem,\n",
    "    seed=config[\"experiment\"][\"seed\"],\n",
    "    generation_limit=config[\"pipeline\"][\"generation_limit\"],\n",
    "    fitness_target=config[\"pipeline\"][\"fitness_target\"],\n",
    "    is_save=True,\n",
    "    save_dir=config[\"experiment\"][\"output_dir\"],\n",
    ")\n",
    "\n",
    "init_state = pipeline.setup()\n",
    "state = pipeline.auto_run(state=init_state)\n",
    "\n",
    "print(f\"\\nTraining finished. Best fitness achieved: {pipeline.best_fitness}\")\n",
    "\n",
    "wandb.finish()\n",
    "\n",
    "state_for_show = state[0] if isinstance(state, tuple) else state\n",
    "\n",
    "# Transform the best genome into network parameters\n",
    "best_genome = pipeline.best_genome\n",
    "\n",
    "# Built-in show method to produce and save a video of the agent\n",
    "pipeline.show(\n",
    "    state=state_for_show,\n",
    "    best=best_genome,\n",
    "    output_type=\"mp4\",\n",
    "    save_path=f\"{OUTPUT_DIR}/video/agent_random_pca_test.mp4\",\n",
    ")\n",
    "\n",
    "# Visualizes the CPPN\n",
    "visualize_cppn(\n",
    "    pipeline=pipeline, \n",
    "    state=state, \n",
    "    save_path=f\"{OUTPUT_DIR}/topology/cppn_random_pca_test.svg\"\n",
    "    )\n",
    "# Visualizes a representation of the neural network in 2D space\n",
    "visualize_nn(\n",
    "    pipeline=pipeline, \n",
    "    state=state, \n",
    "    save_path=f\"{OUTPUT_DIR}/topology/nn_random_pca_test_.svg\", \n",
    "    substrate=active_substrate, \n",
    "    input_coors=input_coors, \n",
    "    hidden_coors=hidden_coors, \n",
    "    output_coors=output_coors, \n",
    "    hidden_depth=config[\"substrate\"][\"hidden_depth\"], \n",
    "    max_weight=config[\"algorithm\"][\"hyperneat\"][\"max_weight\"], \n",
    "    )\n",
    "\n",
    "# all input and output coordinates are logged for further analysis\n",
    "log_coors = input_coors\n",
    "for coor in hidden_coors:\n",
    "    log_coors.append(coor)\n",
    "for coor in output_coors:\n",
    "    log_coors.append(coor)\n",
    "save_coordinates_to_csv(\n",
    "    coordinates=log_coors,\n",
    "    filepath=f\"{OUTPUT_DIR}/coordinates/random_pca_test__io.csv\",\n",
    ")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jax",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
